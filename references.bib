
@article{lundervold_overview_2019,
	title = {An overview of deep learning in medical imaging focusing on {MRI}},
	volume = {29},
	issn = {09393889},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0939388918301181},
	doi = {10.1016/j.zemedi.2018.11.002},
	abstract = {What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artiﬁcial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding ﬁeld we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI.},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Zeitschrift für Medizinische Physik},
	author = {Lundervold, Alexander Selvikvåg and Lundervold, Arvid},
	month = may,
	year = {2019},
	pages = {102--127},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/IV3X7GWQ/Lundervold and Lundervold - 2019 - An overview of deep learning in medical imaging fo.pdf:application/pdf}
}

@article{lustig_sparse_2007,
	title = {Sparse {MRI}: {The} application of compressed sensing for rapid {MR} imaging},
	volume = {58},
	issn = {07403194, 15222594},
	shorttitle = {Sparse {MRI}},
	url = {http://doi.wiley.com/10.1002/mrm.21391},
	doi = {10.1002/mrm.21391},
	language = {en},
	number = {6},
	urldate = {2020-06-24},
	journal = {Magnetic Resonance in Medicine},
	author = {Lustig, Michael and Donoho, David and Pauly, John M.},
	month = dec,
	year = {2007},
	pages = {1182--1195},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/RUZP7JLJ/Lustig et al. - 2007 - Sparse MRI The application of compressed sensing .pdf:application/pdf}
}

@article{zhang_review_2020,
	title = {A {Review} on {Deep} {Learning} in {Medical} {Image} {Reconstruction}},
	volume = {8},
	issn = {2194-668X, 2194-6698},
	url = {http://link.springer.com/10.1007/s40305-019-00287-4},
	doi = {10.1007/s40305-019-00287-4},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Journal of the Operations Research Society of China},
	author = {Zhang, Hai-Miao and Dong, Bin},
	month = jun,
	year = {2020},
	pages = {311--340},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/Q25KULJ7/Zhang and Dong - 2020 - A Review on Deep Learning in Medical Image Reconst.pdf:application/pdf}
}

@incollection{mardani_neural_2018,
	title = {Neural {Proximal} {Gradient} {Descent} for {Compressive} {Imaging}},
	url = {http://papers.nips.cc/paper/8166-neural-proximal-gradient-descent-for-compressive-imaging.pdf},
	urldate = {2020-06-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Mardani, Morteza and Sun, Qingyun and Donoho, David and Papyan, Vardan and Monajemi, Hatef and Vasanawala, Shreyas and Pauly, John},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {9573--9583},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/J8EUUZXS/Mardani et al. - 2018 - Neural Proximal Gradient Descent for Compressive I.pdf:application/pdf}
}

@article{mardani_deep_2019,
	title = {Deep {Generative} {Adversarial} {Neural} {Networks} for {Compressive} {Sensing} {MRI}},
	volume = {38},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/8417964/},
	doi = {10.1109/TMI.2018.2858752},
	abstract = {Undersampled magnetic resonance image (MRI) reconstruction is typically an ill-posed linear inverse task. The time and resource intensive computations require trade offs between accuracy and speed. In addition, state-of-the-art compressed sensing (CS) analytics are not cognizant of the image diagnostic quality. To address these challenges, we propose a novel CS framework that uses generative adversarial networks (GAN) to model the (low-dimensional) manifold of high-quality MR images. Leveraging a mixture of least-squares (LS) GANs and pixel-wise 1/ 2 cost, a deep residual network with skip connections is trained as the generator that learns to remove the aliasing artifacts by projecting onto the image manifold. The LSGAN learns the texture details, while the 1/ 2 cost suppresses high-frequency noise. A discriminator network, which is a multilayer convolutional neural network (CNN), plays the role of a perceptual cost that is then jointly trained based on high quality MR images to score the quality of retrieved images. In the operational phase, an initial aliased estimate (e.g., simply obtained by zero-ﬁlling) is propagated into the trained generator to output the desired reconstruction. This demands very low computational overhead. Extensive evaluations are performed on a large contrast-enhanced MR dataset of pediatric patients. Images rated by expert radiologists corroborate that GANCS retrieves higher quality images with improved ﬁne texture details compared with conventional Wavelet-based and dictionary-learning based CS schemes as well as with deeplearning based schemes using pixel-wise training. In addition, it offers reconstruction times of under a few milliseconds, which is two orders of magnitude faster than current state-of-the-art CS-MRI schemes.},
	language = {en},
	number = {1},
	urldate = {2020-06-26},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Mardani, Morteza and Gong, Enhao and Cheng, Joseph Y. and Vasanawala, Shreyas S. and Zaharchuk, Greg and Xing, Lei and Pauly, John M.},
	month = jan,
	year = {2019},
	pages = {167--179},
	file = {Accepted Version:/home/gabrielziegler/Zotero/storage/26PF7TBN/Mardani et al. - 2019 - Deep Generative Adversarial Neural Networks for Co.pdf:application/pdf}
}

@article{makropoulos_review_2018,
	title = {A review on automatic fetal and neonatal brain {MRI} segmentation},
	volume = {170},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917305451},
	doi = {10.1016/j.neuroimage.2017.06.074},
	abstract = {In recent years, a variety of segmentation methods have been proposed for automatic delineation of the fetal and neonatal brain MRI. These methods aim to deﬁne regions of interest of diﬀerent granularity: brain, tissue types or more localised structures. Diﬀerent methodologies have been applied for this segmentation task and can be classiﬁed into unsupervised, parametric, classiﬁcation, atlas fusion and deformable models. Brain atlases are commonly utilised as training data in the segmentation process. Challenges relating to the image acquisition, the rapid brain development as well as the limited availability of imaging data however hinder this segmentation task. In this paper, we review methods adopted for the perinatal brain and categorise them according to the target population, structures segmented and methodology. We outline diﬀerent methods proposed in the literature and discuss their major contributions. Diﬀerent approaches for the evaluation of the segmentation accuracy and benchmarks used for the segmentation quality are presented. We conclude this review with a discussion on shortcomings in the perinatal domain and possible future directions.},
	language = {en},
	urldate = {2020-06-26},
	journal = {NeuroImage},
	author = {Makropoulos, Antonios and Counsell, Serena J. and Rueckert, Daniel},
	month = apr,
	year = {2018},
	pages = {231--248},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/69M86YJE/Makropoulos et al. - 2018 - A review on automatic fetal and neonatal brain MRI.pdf:application/pdf}
}

@article{radford_unsupervised_2016,
	title = {Unsupervised {Representation} {Learning} with {Deep} {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1511.06434},
	abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
	urldate = {2020-07-03},
	journal = {arXiv:1511.06434 [cs]},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	month = jan,
	year = {2016},
	note = {arXiv: 1511.06434},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/9XRY5RLP/Radford et al. - 2016 - Unsupervised Representation Learning with Deep Con.pdf:application/pdf}
}

@incollection{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Nets}},
	url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
	urldate = {2020-07-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {2672--2680},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/EW979R6X/Goodfellow et al. - 2014 - Generative Adversarial Nets.pdf:application/pdf}
}

@article{liang_deep_2019,
	title = {Deep {MRI} {Reconstruction}: {Unrolled} {Optimization} {Algorithms} {Meet} {Neural} {Networks}},
	shorttitle = {Deep {MRI} {Reconstruction}},
	url = {http://arxiv.org/abs/1907.11711},
	abstract = {Image reconstruction from undersampled k-space data has been playing an important role for fast MRI. Recently, deep learning has demonstrated tremendous success in various fields and also shown potential to significantly speed up MR reconstruction with reduced measurements. This article gives an overview of deep learning-based image reconstruction methods for MRI. Three types of deep learning-based approaches are reviewed, the data-driven, model-driven and integrated approaches. The main structure of each network in three approaches is explained and the analysis of common parts of reviewed networks and differences in-between are highlighted. Based on the review, a number of signal processing issues are discussed for maximizing the potential of deep reconstruction for fast MRI. the discussion may facilitate further development of "optimal" network and performance analysis from a theoretical point of view.},
	urldate = {2020-06-24},
	journal = {arXiv:1907.11711 [physics, stat]},
	author = {Liang, Dong and Cheng, Jing and Ke, Ziwen and Ying, Leslie},
	month = jul,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Signal Processing, Physics - Medical Physics}
}

@phdthesis{miosso_cristiano_jacques_compressive_nodate,
	type = {{PhD} {Thesis}},
	title = {Compressive {Sensing} with {Prior} {Information} {Applied} to {Magnetic} {Resonance} {Imaging}},
	school = {Department of Electrical and Computer Engineering, University of Texas at El Paso (UTEP)},
	author = {Miosso, Cristiano Jacques},
	file = {miosso_phd.pdf:/home/gabrielziegler/Zotero/storage/UVIK74EM/miosso_phd.pdf:application/pdf}
}

@article{miosso_compressive_2009,
	title = {Compressive {Sensing} {Reconstruction} {With} {Prior} {Information} by {Iteratively} {Reweighted} {Least}-{Squares}},
	volume = {57},
	issn = {1053-587X, 1941-0476},
	url = {http://ieeexplore.ieee.org/document/4799125/},
	doi = {10.1109/TSP.2009.2016889},
	abstract = {Iteratively reweighted least-squares (IRLS) algorithms have been successfully used in compressive sensing to reconstruct sparse signals from incomplete linear measurements taken in nonsparse domains. The underlying optimization problem corresponds to ﬁnding the vector that solves the minimization while explaining the measurements, and IRLS allows to easily control the used value of , with effect on the number of required measurements. In this paper, we propose a weighting strategy in the reconstruction method based on IRLS in order to add prior information on the support of the sparse domain. Our simulation results show that the use of prior knowledge about positions of at least some of the nonzero coefﬁcients in the sparse domain leads to a reduction in the number of linear measurements required for unambiguous reconstruction. This reduction occurs for all values of , so that a further reduction can be achieved by decreasing and using prior information. The proposed weighting scheme also reduces the computational complexity with respect to the IRLS with no prior information, both in terms of number of iterations and computation time.},
	language = {en},
	number = {6},
	urldate = {2020-03-30},
	journal = {IEEE Transactions on Signal Processing},
	author = {Miosso, C.J. and von Borries, R. and Argaez, M. and Velazquez, L. and Quintero, C. and Potes, C.M.},
	month = jun,
	year = {2009},
	pages = {2424--2431},
	file = {Miosso et al. - 2009 - Compressive Sensing Reconstruction With Prior Info.pdf:/home/gabrielziegler/Zotero/storage/HT2FZJKR/Miosso et al. - 2009 - Compressive Sensing Reconstruction With Prior Info.pdf:application/pdf}
}

@incollection{yang_deep_2016,
	title = {Deep {ADMM}-{Net} for {Compressive} {Sensing} {MRI}},
	url = {http://papers.nips.cc/paper/6406-deep-admm-net-for-compressive-sensing-mri.pdf},
	urldate = {2020-06-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {yang, yan and Sun, Jian and Li, Huibin and Xu, Zongben},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {10--18},
	file = {NIPS Full Text PDF:/home/gabrielziegler/Zotero/storage/HCRTT2SI/yang et al. - 2016 - Deep ADMM-Net for Compressive Sensing MRI.pdf:application/pdf;NIPS Snapshot:/home/gabrielziegler/Zotero/storage/ATV4HPWZ/6406-deep-admm-net-for-compressive-sensing-mri.html:text/html}
}

@article{donoho_compressed_2006,
	title = {Compressed sensing},
	volume = {52},
	issn = {0018-9448},
	url = {http://ieeexplore.ieee.org/document/1614066/},
	doi = {10.1109/TIT.2006.871582},
	abstract = {Suppose is an unknown vector in (a digital image or signal); we plan to measure general linear functionals of and then reconstruct. If is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure deﬁned here, the number of measurements can be dramatically smaller than the size . Thus, certain natural classes of images with pixels need only = ( 1 4 log5 2( )) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual pixel samples.},
	language = {en},
	number = {4},
	urldate = {2020-06-28},
	journal = {IEEE Transactions on Information Theory},
	author = {Donoho, D.L.},
	month = apr,
	year = {2006},
	pages = {1289--1306},
	file = {Donoho - 2006 - Compressed sensing.pdf:/home/gabrielziegler/Zotero/storage/T4Y59U8U/Donoho - 2006 - Compressed sensing.pdf:application/pdf}
}

@article{kabanikhin_definitions_2008,
	title = {Definitions and examples of inverse and ill-posed problems},
	volume = {16},
	issn = {0928-0219, 1569-3945},
	url = {https://www.degruyter.com/view/j/jiip.2008.16.issue-4/jiip.2008.019/jiip.2008.019.xml},
	doi = {10.1515/JIIP.2008.019},
	abstract = {The terms “inverse problems” and “ill-posed problems” have been steadily and surely gaining popularity in modern science since the middle of the 20th century. A little more than ﬁfty years of studying problems of this kind have shown that a great number of problems from various branches of classical mathematics (computational algebra, differential and integral equations, partial differential equations, functional analysis) can be classiﬁed as inverse or ill-posed, and they are among the most complicated ones (since they are unstable and usually nonlinear). At the same time, inverse and ill-posed problems began to be studied and applied systematically in physics, geophysics, medicine, astronomy, and all other areas of knowledge where mathematical methods are used. The reason is that solutions to inverse problems describe important properties of media under study, such as density and velocity of wave propagation, elasticity parameters, conductivity, dielectric permittivity and magnetic permeability, and properties and location of inhomogeneities in inaccessible areas, etc.},
	language = {en},
	number = {4},
	urldate = {2020-06-29},
	journal = {Journal of Inverse and Ill-posed Problems},
	author = {Kabanikhin, S. I.},
	month = jan,
	year = {2008},
	file = {Kabanikhin - 2008 - Definitions and examples of inverse and ill-posed .pdf:/home/gabrielziegler/Zotero/storage/9LZBXJZC/Kabanikhin - 2008 - Definitions and examples of inverse and ill-posed .pdf:application/pdf}
}

@book{bryan_introduction_2009,
	address = {Cambridge},
	title = {Introduction to the {Science} of {Medical} {Imaging}},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Bryan, R Nick},
	year = {2009},
	file = {Bryan - Introduction to the Science of Medical Imaging.pdf:/home/gabrielziegler/Zotero/storage/VHVQP73I/Bryan - Introduction to the Science of Medical Imaging.pdf:application/pdf}
}

@article{dias_metodos_nodate,
	title = {Métodos para {Reconstrução} de {Imagens} de {Tomografia} da {Coroa} {Solar} {Baseados} em},
	language = {pt},
	author = {Dias, Daniele},
	pages = {82},
	file = {Dias - Métodos para Reconstrução de Imagens de Tomografia.pdf:/home/gabrielziegler/Zotero/storage/HVWM76WR/Dias - Métodos para Reconstrução de Imagens de Tomografia.pdf:application/pdf}
}

@inproceedings{devlin_bert_2019,
	address = {Minneapolis, Minnesota},
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {https://www.aclweb.org/anthology/N19-1423},
	doi = {10.18653/v1/N19-1423},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2020-07-28},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = jun,
	year = {2019},
	pages = {4171--4186},
	file = {Full Text PDF:/home/gabrielziegler/Zotero/storage/C645MQ6Y/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf}
}

@article{wan_regularization_nodate,
	title = {Regularization of {Neural} {Networks} using {DropConnect}},
	abstract = {We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models.},
	language = {en},
	author = {Wan, Li and Zeiler, Matthew and Zhang, Sixin and {Yann LeCun}},
	pages = {12},
	file = {Wan et al. - Regularization of Neural Networks using DropConnec.pdf:/home/gabrielziegler/Zotero/storage/4BTAM5HN/Wan et al. - Regularization of Neural Networks using DropConnec.pdf:application/pdf}
}

@inproceedings{kim_enhancing_2019,
	address = {Copenhagen Denmark},
	title = {Enhancing {VAEs} for collaborative filtering: flexible priors \& gating mechanisms},
	isbn = {978-1-4503-6243-6},
	shorttitle = {Enhancing {VAEs} for collaborative filtering},
	url = {https://dl.acm.org/doi/10.1145/3298689.3347015},
	doi = {10.1145/3298689.3347015},
	language = {en},
	urldate = {2020-07-28},
	booktitle = {Proceedings of the 13th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Kim, Daeryong and Suh, Bongwon},
	month = sep,
	year = {2019},
	pages = {403--407},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/WML5YN8A/Kim and Suh - 2019 - Enhancing VAEs for collaborative filtering flexib.pdf:application/pdf}
}

@book{patterson_deep_2017,
	address = {Beijing},
	title = {Deep {Learning}: {A} {Practitioner}'s {Approach}},
	isbn = {978-1-4919-1425-0},
	url = {https://www.safaribooksonline.com/library/view/deep-learning/9781491924570/},
	abstract = {Although interest in machine learning has reached a high point, lofty expectations often scuttle projects before they get very far. How can machine learning—especially deep neural networks—make a real difference in your organization? This hands-on guide not only provides the most practical information available on the subject, but also helps you get started building efficient deep learning networks. The authors provide theory on deep learning before introducing their open-source Deeplearning4j (DL4J) library for developing production-class workflows. Through real-world examples, you will learn methods and strategies for training deep network architectures and running deep learning workflows on Spark and Hadoop with DL4J.},
	publisher = {O'Reilly},
	author = {Patterson, Josh and Gibson, Adam},
	year = {2017},
	keywords = {01841 102 safari book numerical ai software development learn java tool},
	file = {Josh Patterson, Adam Gibson - Deep Learning_ A Practitioner’s Approach (2017, O’Reilly Media) - libgen.lc.pdf:/home/gabrielziegler/Zotero/storage/QJ825QMM/Josh Patterson, Adam Gibson - Deep Learning_ A Practitioner’s Approach (2017, O’Reilly Media) - libgen.lc.pdf:application/pdf}
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	file = {Yoshua Bengio, Ian Goodfellow - Deep learning (2016, The MIT Press).pdf:/home/gabrielziegler/Zotero/storage/CFQURPIU/Yoshua Bengio, Ian Goodfellow - Deep learning (2016, The MIT Press).pdf:application/pdf}
}

@book{buduma_fundamentals_2017,
	edition = {1st},
	title = {Fundamentals of {Deep} {Learning}: {Designing} {Next}-{Generation} {Machine} {Intelligence} {Algorithms}},
	isbn = {1-4919-2561-2},
	publisher = {O’Reilly Media, Inc.},
	author = {Buduma, Nikhil and Locascio, Nicholas},
	year = {2017},
	file = {Buduma and Locascio - Fundamentals of Deep Learning.pdf:/home/gabrielziegler/Zotero/storage/JX43EYPU/Buduma and Locascio - Fundamentals of Deep Learning.pdf:application/pdf}
}

@article{rani_systematic_2018,
	title = {A {Systematic} {Review} of {Compressive} {Sensing}: {Concepts}, {Implementations} and {Applications}},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {A {Systematic} {Review} of {Compressive} {Sensing}},
	url = {http://ieeexplore.ieee.org/document/8260873/},
	doi = {10.1109/ACCESS.2018.2793851},
	abstract = {Compressive Sensing (CS) is a new sensing modality which compresses the signal being acquired at the time of sensing. Signals can have sparse or compressible representation either in original domain or in some transform domain. Relying on the sparsity of the signals, CS allows us to sample the signal at a rate much below the Nyquist sampling rate. Also, the varied reconstruction algorithms of CS can faithfully reconstruct the original signal back from fewer compressive measurements. This fact has stimulated research interest towards the use of CS in the several ﬁelds like magnetic resonance imaging, high speed video acquisition, ultrawideband (UWB) communication, etc. This survey paper reviews the basic theoretical concepts underlying CS. To bridge the gap between theory and practicality of CS, different CS acquisition strategies and reconstruction approaches are elaborated systematically in this paper. The major application areas where CS is currently being used are reviewed here. This paper also highlights some of the challenges and research directions in this ﬁeld.},
	language = {en},
	urldate = {2020-08-18},
	journal = {IEEE Access},
	author = {Rani, Meenu and Dhok, S. B. and Deshmukh, R. B.},
	year = {2018},
	pages = {4875--4894},
	file = {Rani et al. - 2018 - A Systematic Review of Compressive Sensing Concep.pdf:/home/gabrielziegler/Zotero/storage/7KS2MY84/Rani et al. - 2018 - A Systematic Review of Compressive Sensing Concep.pdf:application/pdf}
}

@article{ye_compressed_2019,
	title = {Compressed sensing {MRI}: a review from signal processing perspective},
	volume = {1},
	issn = {2524-4426},
	shorttitle = {Compressed sensing {MRI}},
	url = {https://bmcbiomedeng.biomedcentral.com/articles/10.1186/s42490-019-0006-z},
	doi = {10.1186/s42490-019-0006-z},
	abstract = {Magnetic resonance imaging (MRI) is an inherently slow imaging modality, since it acquires multi-dimensional kspace data through 1-D free induction decay or echo signals. This often limits the use of MRI, especially for high resolution or dynamic imaging. Accordingly, many investigators has developed various acceleration techniques to allow fast MR imaging. For the last two decades, one of the most important breakthroughs in this direction is the introduction of compressed sensing (CS) that allows accurate reconstruction from sparsely sampled k-space data. The recent FDA approval of compressed sensing products for clinical scans clearly reflect the maturity of this technology. Therefore, this paper reviews the basic idea of CS and how this technology have been evolved for various MR imaging problems.},
	language = {en},
	number = {1},
	urldate = {2020-08-18},
	journal = {BMC Biomedical Engineering},
	author = {Ye, Jong Chul},
	month = dec,
	year = {2019},
	pages = {8},
	file = {Ye - 2019 - Compressed sensing MRI a review from signal proce.pdf:/home/gabrielziegler/Zotero/storage/2S4TIBQB/Ye - 2019 - Compressed sensing MRI a review from signal proce.pdf:application/pdf}
}

@article{candes_introduction_2008,
	title = {An {Introduction} {To} {Compressive} {Sampling}},
	volume = {25},
	issn = {1053-5888},
	url = {http://ieeexplore.ieee.org/document/4472240/},
	doi = {10.1109/MSP.2007.914731},
	language = {en},
	number = {2},
	urldate = {2020-08-18},
	journal = {IEEE Signal Processing Magazine},
	author = {Candes, E.J. and Wakin, M.B.},
	month = mar,
	year = {2008},
	pages = {21--30},
	file = {Candes and Wakin - 2008 - An Introduction To Compressive Sampling.pdf:/home/gabrielziegler/Zotero/storage/J5IJ2P6S/Candes and Wakin - 2008 - An Introduction To Compressive Sampling.pdf:application/pdf}
}

@inproceedings{miosso_compressive_2009-1,
	address = {Pacific Grove, CA, USA},
	title = {Compressive sensing method for improved reconstruction of gradient-sparse magnetic resonance images},
	isbn = {978-1-4244-5825-7},
	url = {http://ieeexplore.ieee.org/document/5469970/},
	doi = {10.1109/ACSSC.2009.5469970},
	abstract = {We propose a compressive sensing method for reconstructing gradient-sparse magnetic resonance (MR) images based on the pre-ﬁltering of the input signals in the k-space. A set of ﬁltered versions of the image is reconstructed using the available k-space samples, and a ﬁnal reconstruction stage generates the desired image from the ﬁltered versions. Our experiments, conducted over real MR images and angiograms, show that the proposed method improves the reconstruction over the total-variation minimization, in terms of signal-to-noise ratio and computation time. The proposed method is particularly appropriate for computing MR angiograms, which are typically sparse under the ﬁnite-differences operation.},
	language = {en},
	urldate = {2020-08-28},
	booktitle = {2009 {Conference} {Record} of the {Forty}-{Third} {Asilomar} {Conference} on {Signals}, {Systems} and {Computers}},
	publisher = {IEEE},
	author = {Miosso, C. J. and von Borries, R. and Pierluissi, J. H.},
	year = {2009},
	pages = {799--806},
	file = {Miosso et al. - 2009 - Compressive sensing method for improved reconstruc.pdf:/home/gabrielziegler/Zotero/storage/UV2MDUG6/Miosso et al. - 2009 - Compressive sensing method for improved reconstruc.pdf:application/pdf}
}

@inproceedings{chen_brain_2018,
	address = {Washington, DC},
	title = {Brain {MRI} super resolution using {3D} deep densely connected neural networks},
	isbn = {978-1-5386-3636-7},
	url = {https://ieeexplore.ieee.org/document/8363679/},
	doi = {10.1109/ISBI.2018.8363679},
	abstract = {Magnetic resonance image (MRI) in high spatial resolution provides detailed anatomical information and is often necessary for accurate quantitative analysis. However, high spatial resolution typically comes at the expense of longer scan time, less spatial coverage, and lower signal to noise ratio (SNR). Single Image Super-Resolution (SISR), a technique aimed to restore high-resolution (HR) details from one single low-resolution (LR) input image, has been improved dramatically by recent breakthroughs in deep learning. In this paper, we introduce a new neural network architecture, 3D Densely Connected Super-Resolution Networks (DCSRN) to restore HR features of structural brain MR images. Through experiments on a dataset with 1,113 subjects, we demonstrate that our network outperforms bicubic interpolation as well as other deep learning methods in restoring 4x resolution-reduced images.},
	language = {en},
	urldate = {2020-09-29},
	booktitle = {2018 {IEEE} 15th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2018)},
	publisher = {IEEE},
	author = {Chen, Yuhua and Xie, Yibin and Zhou, Zhengwei and Shi, Feng and Christodoulou, Anthony G. and Li, Debiao},
	month = apr,
	year = {2018},
	pages = {739--742},
	file = {Chen et al. - 2018 - Brain MRI super resolution using 3D deep densely c.pdf:/home/gabrielziegler/Zotero/storage/6IIIWACX/Chen et al. - 2018 - Brain MRI super resolution using 3D deep densely c.pdf:application/pdf}
}

@article{yang_dagan_2018,
	title = {{DAGAN}: {Deep} {De}-{Aliasing} {Generative} {Adversarial} {Networks} for {Fast} {Compressed} {Sensing} {MRI} {Reconstruction}},
	volume = {37},
	issn = {0278-0062, 1558-254X},
	shorttitle = {{DAGAN}},
	url = {https://ieeexplore.ieee.org/document/8233175/},
	doi = {10.1109/TMI.2017.2785879},
	abstract = {Compressed Sensing Magnetic Resonance Imaging (CS-MRI) enables fast acquisition, which is highly desirable for numerous clinical applications. This can not only reduce the scanning cost and ease patient burden, but also potentially reduce motion artefacts and the effect of contrast washout, thus yielding better image quality. Different from parallel imaging based fast MRI, which utilises multiple coils to simultaneously receive MR signals, CS-MRI breaks the Nyquist-Shannon sampling barrier to reconstruct MRI images with much less required raw data. This paper provides a deep learning based strategy for reconstruction of CS-MRI, and bridges a substantial gap between conventional non-learning methods working only on data from a single image, and prior knowledge from large training datasets. In particular, a novel conditional Generative Adversarial Networks-based model (DAGAN) is proposed to reconstruct CS-MRI. In our DAGAN architecture, we have designed a reﬁnement learning method to stabilise our U-Net based generator, which provides an endto-end network to reduce aliasing artefacts. To better preserve texture and edges in the reconstruction, we have coupled the adversarial loss with an innovative content loss. In addition, we incorporate frequency domain information to enforce similarity in both the image and frequency domains. We have performed comprehensive comparison studies with both conventional CSMRI reconstruction methods and newly investigated deep learning approaches. Compared to these methods, our DAGAN method provides superior reconstruction with preserved perceptual image details. Furthermore, each image is reconstructed in about 5 ms, which is suitable for real-time processing.},
	language = {en},
	number = {6},
	urldate = {2020-10-06},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Yang, Guang and Yu, Simiao and Dong, Hao and Slabaugh, Greg and Dragotti, Pier Luigi and Ye, Xujiong and Liu, Fangde and Arridge, Simon and Keegan, Jennifer and Guo, Yike and Firmin, David},
	month = jun,
	year = {2018},
	pages = {1310--1321},
	file = {Yang et al. - 2018 - DAGAN Deep De-Aliasing Generative Adversarial Net.pdf:/home/gabrielziegler/Zotero/storage/ZZE822BR/Yang et al. - 2018 - DAGAN Deep De-Aliasing Generative Adversarial Net.pdf:application/pdf}
}

@article{gupta_super-resolution_2020,
	title = {Super-{Resolution} using {GANs} for {Medical} {Imaging}},
	volume = {173},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050920315076},
	doi = {10.1016/j.procs.2020.06.005},
	abstract = {GAebnsetrraatcitve Adversarial Models (GANs) have been quite popular and are currently and active area of research. They can be used for generative new data and study adversarial samples and attacks. We have used the similar approach to apply super-resolution to mGeendeicraatlivime aAgdevs.eIrnsaRriaadl iMoloodgeylsM(GRIAiNs sa)choamvemboenelyn uqsueitdempoetphuoldartoanpdroadreucceurmreendtilcyalanimd aagcitnivgebaurtetahoeflirmesietaatricohn.sTohfelyabcaenqubiepmuseendt afonrdgheenaelrtahtihvaeznaerdwodfabtaeianngdisntuadnyMadRvIerrsaadriiaatliosnamepnvleisroannmdeantttatcokso.bWtaienhgaovoedusqeudaltihtye ssicmanilsarleaapdprtooalcohwteor aqpupallyitsyuspcearn-rsesaonldutaiolsnotiot tmakeedsicaalloimt aogfetsim. Ien tRoagdeiot laoghyigMh-RreIsoisluaticoonmdmatoan. lTyhuissepdrombeltehmodcaton pbreodsuoclveemd ebdyicuaslinimg asguipnegr-bruestothluetiloimn iutastiinognsdeoefplalbeaerqnuinipgmaesnat panodst-hperaolctheshsianzgarsdteopf tboeiinmgprinovaenthMeRrIesroalduitaitoinonofenthveirosncamnesn. tStuopoerb-traeisnolguotoiodnqiusaaliptyroscceasnssolfeagdentoerlaotwinegrhqiugahleitryresscoalnustiaonndimalasogeist ftarokmes laowloetroref stoimluetioton gdeattaa. Fhoigrhth-riess,owluetaioren pdraotpa.osTinhgisapgroebnleermativceanadbveesrsoalvrieadl nbeytwuosirnkgarscuhpieter-crteusroeluwtihoinchuissinagdudaelepnelueraarlnninegtwaosrka dpeossitg-pnreodcetossignegnesrtaetpe tloifiemlikperoivmeatgheesr.eIsnoltuhtiisondeoefpthleearsncianngs.aSlguopreirth-rmes,otlwutoionneuisraal pnreotcweosrskosfcgoemnpereatetinwgithhigehaecrhroesthoelurttioonimimparogvees afrlotemrnlaotwiveerlyr.eGsoilvuetnioan tdraatian.inFgorsetht,ist,hwiseteacrehnpirqoupeosleinagrnas gtoengeernaetirvaeteadnveewrsdaaritaalwneitthwtohrek saarmcheitsetcattuisrteicwshaischthies atradiunailnngesuerta.lTnoetawpoprlyk tdheissigtencehdntioqugeentoeroauter plirfoeblilkeemimstaagteems.eInnt twhies adreeeupsilneagrngienngeraaltgoorriatshmth,etnweotwnoerukratloniemtwproorvkes tchoemrpeesoteluwtiiotnh aenacdhdoistchreirmtionaitmorpraosvea nalettewrnoartkivteolyt.raGinivgeennaertartaoinr ibnegttseer.t,Wtheisutseecdhtnriaqnusefelrealernarsntionggeinneorautregneenweradtaivtaewneituhrathl enestawmoerkstaantidstitcrasinasintgheoutrradinisincgrimseitn.aTtoorafpropmly sthcirsattcehchannidquuesintog othuer pperorcbelepmtuasltalotesms [e1n]t two etraairne ouusirnngetgwenoerkra. tTohr iasswthilel hneeltpwionrkimtopriomvipnrgovtehethpeerrfeosromluatniocne oafndthedinscertwimoirnka.tWoreaasrea unseitnwgorLkutnogtMraiRnIgsecnaenrsatoofrtbuebtetrecr.uWloseisusweidthtraanssefteorfle2a1r6niMngRiInsoaumrpgleesnecroantitvaeinnineguraarlonuentdw6o0rk-1a3n0dcthraainnninelgs oeuarchdiasncdrimeaicnhatcohrafnronmel hscarvaitncgh 5a1n2dxu5s1i2ngditmheepnesirocneps.tual loss [1] to train our network. This will help in improving the performance of the network. We are using Lung MRI scans of tuberculosis with a set of 216 MRI samples containing around 60-130 channels each and each channel hcav2i0n2g05T12hxe5A1u2thdoimrse.nPsuiobnliss.hed by Elsevier B.V.},
	language = {en},
	urldate = {2020-10-07},
	journal = {Procedia Computer Science},
	author = {Gupta, Rohit and Sharma, Anurag and Kumar, Anupam},
	year = {2020},
	pages = {28--35},
	file = {Gupta et al. - 2020 - Super-Resolution using GANs for Medical Imaging.pdf:/home/gabrielziegler/Zotero/storage/ZX9VN576/Gupta et al. - 2020 - Super-Resolution using GANs for Medical Imaging.pdf:application/pdf}
}

@article{cole_unsupervised_nodate,
	title = {Unsupervised {MRI} {Reconstruction} with {Generative} {Adversarial} {Networks}},
	abstract = {Deep learning-based image reconstruction methods have achieved promising results across multiple MRI applications. However, most approaches require largescale fully-sampled ground truth data for supervised training. Acquiring fully-sampled data is often either difficult or impossible, particularly for dynamic contrast enhancement (DCE), 3D cardiac cine, and 4D flow. We present a deep learning framework for MRI reconstruction without any fully-sampled data using generative adversarial networks. We test the proposed method in two scenarios: retrospectively undersampled fast spin echo knee exams and prospectively undersampled abdominal DCE. The method recovers more anatomical structure compared to conventional methods.},
	language = {en},
	author = {Cole, Elizabeth K and Pauly, John M and Vasanawala, Shreyas S and Ong, Frank},
	pages = {8},
	file = {Cole et al. - Unsupervised MRI Reconstruction with Generative Ad.pdf:/home/gabrielziegler/Zotero/storage/BYPKAB42/Cole et al. - Unsupervised MRI Reconstruction with Generative Ad.pdf:application/pdf}
}

@article{knoll_advancing_2020,
	title = {Advancing machine learning for {MR} image reconstruction with an open competition: {Overview} of the 2019 {fastMRI} challenge},
	volume = {84},
	issn = {0740-3194, 1522-2594},
	shorttitle = {Advancing machine learning for {MR} image reconstruction with an open competition},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/mrm.28338},
	doi = {10.1002/mrm.28338},
	abstract = {Purpose: To advance research in the field of machine learning for MR image reconstruction with an open challenge.
Methods: We provided participants with a dataset of raw k-space data from 1,594 consecutive clinical exams of the knee. The goal of the challenge was to reconstruct images from these data. In order to strike a balance between realistic data and a shallow learning curve for those not already familiar with MR image reconstruction, we ran multiple tracks for multi-coil and single-coil data. We performed a two-stage evaluation based on quantitative image metrics followed by evaluation by a panel of radiologists. The challenge ran from June to December of 2019.
Results: We received a total of 33 challenge submissions. All participants chose to submit results from supervised machine learning approaches.
Conclusions: The challenge led to new developments in machine learning for image reconstruction, provided insight into the current state of the art in the field, and highlighted remaining hurdles for clinical adoption.},
	language = {en},
	number = {6},
	urldate = {2020-10-11},
	journal = {Magnetic Resonance in Medicine},
	author = {Knoll, Florian and Murrell, Tullie and Sriram, Anuroop and Yakubova, Nafissa and Zbontar, Jure and Rabbat, Michael and Defazio, Aaron and Muckley, Matthew J. and Sodickson, Daniel K. and Zitnick, C. Lawrence and Recht, Michael P.},
	month = dec,
	year = {2020},
	pages = {3054--3070},
	file = {Knoll et al. - 2020 - Advancing machine learning for MR image reconstruc.pdf:/home/gabrielziegler/Zotero/storage/7VLIN5G4/Knoll et al. - 2020 - Advancing machine learning for MR image reconstruc.pdf:application/pdf}
}

@article{zbontar_fastmri_2019,
	title = {{fastMRI}: {An} {Open} {Dataset} and {Benchmarks} for {Accelerated} {MRI}},
	shorttitle = {{fastMRI}},
	url = {http://arxiv.org/abs/1811.08839},
	abstract = {Accelerating Magnetic Resonance Imaging (MRI) by taking fewer measurements has the potential to reduce medical costs, minimize stress to patients and make MRI possible in applications where it is currently prohibitively slow or expensive. We introduce the fastMRI dataset, a large-scale collection of both raw MR measurements and clinical MR images, that can be used for training and evaluation of machine-learning approaches to MR image reconstruction. By introducing standardized evaluation criteria and a freely-accessible dataset, our goal is to help the community make rapid advances in the state of the art for MR image reconstruction. We also provide a self-contained introduction to MRI for machine learning researchers with no medical imaging background.},
	urldate = {2020-10-11},
	journal = {arXiv:1811.08839 [physics, stat]},
	author = {Zbontar, Jure and Knoll, Florian and Sriram, Anuroop and Murrell, Tullie and Huang, Zhengnan and Muckley, Matthew J. and Defazio, Aaron and Stern, Ruben and Johnson, Patricia and Bruno, Mary and Parente, Marc and Geras, Krzysztof J. and Katsnelson, Joe and Chandarana, Hersh and Zhang, Zizhao and Drozdzal, Michal and Romero, Adriana and Rabbat, Michael and Vincent, Pascal and Yakubova, Nafissa and Pinkerton, James and Wang, Duo and Owens, Erich and Zitnick, C. Lawrence and Recht, Michael P. and Sodickson, Daniel K. and Lui, Yvonne W.},
	month = dec,
	year = {2019},
	note = {arXiv: 1811.08839},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Signal Processing, Physics - Medical Physics},
	file = {arXiv Fulltext PDF:/home/gabrielziegler/Zotero/storage/54LQZ9W2/Zbontar et al. - 2019 - fastMRI An Open Dataset and Benchmarks for Accele.pdf:application/pdf;arXiv.org Snapshot:/home/gabrielziegler/Zotero/storage/5CYIN98L/1811.html:text/html}
}

@article{hyun_deep_2018,
	title = {Deep learning for undersampled {MRI} reconstruction},
	volume = {63},
	issn = {1361-6560},
	url = {https://iopscience.iop.org/article/10.1088/1361-6560/aac71a},
	doi = {10.1088/1361-6560/aac71a},
	abstract = {This paper presents a deep learning method for faster magnetic resonance imaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and provides a rationale for why the proposed approach works well. Uniform subsampling is used in the time-consuming phaseencoding direction to capture high-resolution image information, while permitting the imagefolding problem dictated by the Poisson summation formula. To deal with the localization uncertainty due to image folding, a small number of low-frequency k-space data are added. Training the deep learning net involves input and output images that are pairs of the Fourier transforms of the subsampled and fully sampled k-space data. Our experiments show the remarkable performance of the proposed method; only 29\% of the k-space data can generate images of high quality as effectively as standard MRI reconstruction with the fully sampled data.},
	language = {en},
	number = {13},
	urldate = {2020-11-02},
	journal = {Physics in Medicine \& Biology},
	author = {Hyun, Chang Min and Kim, Hwa Pyung and Lee, Sung Min and Lee, Sungchul and Seo, Jin Keun},
	month = jun,
	year = {2018},
	pages = {135007},
	file = {Hyun et al. - 2018 - Deep learning for undersampled MRI reconstruction.pdf:/home/gabrielziegler/Zotero/storage/6QD3DX7E/Hyun et al. - 2018 - Deep learning for undersampled MRI reconstruction.pdf:application/pdf}
}

@article{lauterbur_image_1973,
	title = {Image {Formation} by {Induced} {Local} {Interactions}: {Examples} {Employing} {Nuclear} {Magnetic} {Resonance}},
	volume = {242},
	issn = {0028-0836, 1476-4687},
	shorttitle = {Image {Formation} by {Induced} {Local} {Interactions}},
	url = {http://www.nature.com/articles/242190a0},
	doi = {10.1038/242190a0},
	language = {en},
	number = {5394},
	urldate = {2020-11-02},
	journal = {Nature},
	author = {Lauterbur, P. C.},
	month = mar,
	year = {1973},
	pages = {190--191},
	file = {Lauterbur - 1973 - Image Formation by Induced Local Interactions Exa.pdf:/home/gabrielziegler/Zotero/storage/5G7XDV7W/Lauterbur - 1973 - Image Formation by Induced Local Interactions Exa.pdf:application/pdf}
}

@article{knoll_fastmri_2020,
	title = {{fastMRI}: {A} {Publicly} {Available} {Raw} k-{Space} and {DICOM} {Dataset} of {Knee} {Images} for {Accelerated} {MR} {Image} {Reconstruction} {Using} {Machine} {Learning}.},
	volume = {2 1},
	journal = {Radiology. Artificial intelligence},
	author = {Knoll, Florian and Zbontar, J. and Sriram, Anuroop and Muckley, M. and Bruno, M. and Defazio, Aaron and Parente, Marc and Geras, Krzysztof J. and Katsnelson, Joe and Chandarana, H. and Zhang, Zi-zhao and Drozdzalv, Michal and Romero, A. and Rabbat, M. and Vincent, Pascal and Pinkerton, James T. and Wang, D. and Yakubova, N. and Owens, E. and Zitnick, C. L. and Recht, M. and Sodickson, D. and Lui, Y.},
	year = {2020},
	pages = {e190007}
}

@incollection{salimans_improved_2016,
	title = {Improved {Techniques} for {Training} {GANs}},
	url = {http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf},
	urldate = {2020-11-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {2234--2242},
	file = {NIPS Full Text PDF:/home/gabrielziegler/Zotero/storage/U9VAW9WU/Salimans et al. - 2016 - Improved Techniques for Training GANs.pdf:application/pdf;NIPS Snapshot:/home/gabrielziegler/Zotero/storage/QEN6DDM8/6125-improved-techniques-for-training-gans.html:text/html}
}

@article{sandino_deep_nodate,
	title = {Deep convolutional neural networks for accelerated dynamic magnetic resonance imaging},
	abstract = {Dynamic magnetic resonance imaging (MRI) scans can be accelerated by utilizing compressed sensing (CS) reconstruction methods that allow for diagnostic quality images to be generated from undersampled data. Unfortunately, CS reconstruction is time-consuming, requiring hours between a dynamic MRI scan and image availability for diagnosis. In this work, we train a convolutional neural network (CNN) to perform fast reconstruction of severely undersampled dynamic cardiac MRI data, and we explore the utility of CNNs for further accelerating dynamic MRI scan times. Compared to state-of-the-art CS reconstruction techniques, our CNN achieves reconstruction speeds that are 150x faster without signiﬁcant loss of image quality. Additionally, preliminary results suggest that CNNs may allow scan times that are 2x faster than those allowed by CS.},
	language = {en},
	author = {Sandino, Christopher M and Dixit, Neerav and Cheng, Joseph Y and Vasanawala, Shreyas S},
	pages = {8},
	file = {Sandino et al. - Deep convolutional neural networks for accelerated.pdf:/home/gabrielziegler/Zotero/storage/XVPCJMFU/Sandino et al. - Deep convolutional neural networks for accelerated.pdf:application/pdf}
}

@inproceedings{wang_high-resolution_2018,
	address = {Salt Lake City, UT, USA},
	title = {High-{Resolution} {Image} {Synthesis} and {Semantic} {Manipulation} with {Conditional} {GANs}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8579015/},
	doi = {10.1109/CVPR.2018.00917},
	urldate = {2020-11-03},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
	month = jun,
	year = {2018},
	pages = {8798--8807},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/FTCVYZN3/Wang et al. - 2018 - High-Resolution Image Synthesis and Semantic Manip.pdf:application/pdf}
}

@article{mota_compressed_2017,
	title = {Compressed {Sensing} {With} {Prior} {Information}: {Strategies}, {Geometry}, and {Bounds}},
	volume = {63},
	issn = {0018-9448, 1557-9654},
	shorttitle = {Compressed {Sensing} {With} {Prior} {Information}},
	url = {https://ieeexplore.ieee.org/document/7904593/},
	doi = {10.1109/TIT.2017.2695614},
	number = {7},
	urldate = {2020-11-04},
	journal = {IEEE Transactions on Information Theory},
	author = {Mota, Joao F. C. and Deligiannis, Nikos and Rodrigues, Miguel R. D.},
	month = jul,
	year = {2017},
	pages = {4472--4496},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/PVLWE8BE/Mota et al. - 2017 - Compressed Sensing With Prior Information Strateg.pdf:application/pdf}
}

@inproceedings{zhang_compressed_2017,
	address = {Aachen, Germany},
	title = {Compressed sensing with prior information via maximizing correlation},
	isbn = {978-1-5090-4096-4},
	url = {http://ieeexplore.ieee.org/document/8006522/},
	doi = {10.1109/ISIT.2017.8006522},
	urldate = {2020-11-04},
	booktitle = {2017 {IEEE} {International} {Symposium} on {Information} {Theory} ({ISIT})},
	publisher = {IEEE},
	author = {Zhang, Xu and Cui, Wei and Liu, Yulong},
	month = jun,
	year = {2017},
	pages = {221--225},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/TLHPVZF3/Zhang et al. - 2017 - Compressed sensing with prior information via maxi.pdf:application/pdf}
}

@article{kutyniok_compressed_nodate,
	title = {Compressed {Sensing}},
	language = {en},
	author = {Kutyniok, Gitta and Eldar, Yonina C},
	pages = {558},
	file = {Kutyniok and Eldar - Compressed Sensing.pdf:/home/gabrielziegler/Zotero/storage/QC6ERCHV/Kutyniok and Eldar - Compressed Sensing.pdf:application/pdf}
}

@book{carmi_compressed_2014,
	address = {Berlin, Heidelberg},
	series = {Signals and {Communication} {Technology}},
	title = {Compressed {Sensing} \& {Sparse} {Filtering}},
	isbn = {978-3-642-38397-7 978-3-642-38398-4},
	url = {http://link.springer.com/10.1007/978-3-642-38398-4},
	language = {en},
	urldate = {2020-11-05},
	publisher = {Springer Berlin Heidelberg},
	editor = {Carmi, Avishy Y. and Mihaylova, Lyudmila and Godsill, Simon J.},
	year = {2014},
	doi = {10.1007/978-3-642-38398-4},
	file = {Carmi et al. - 2014 - Compressed Sensing & Sparse Filtering.pdf:/home/gabrielziegler/Zotero/storage/2KI63Z4X/Carmi et al. - 2014 - Compressed Sensing & Sparse Filtering.pdf:application/pdf}
}

@article{shepp_fourier_1974,
	title = {The {Fourier} reconstruction of a head section},
	volume = {21},
	doi = {10.1109/TNS.1974.6499235},
	number = {3},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Shepp, L. A. and Logan, B. F.},
	year = {1974},
	pages = {21--43}
}

@misc{oreilly_gan,
	title = {Deep convolutional generative adversarial networks with TensorFlow},
	author = {Dominic Monn},
    note = {Available at: \url{https://www.oreilly.com/content/deep-convolutional-generative-adversarial-networks-with-tensorflow/}. Last access on November 18th, 2020},
	year = {2017}
}
