
@article{miosso_compressive_2009,
	title = {Compressive {Sensing} {Reconstruction} {With} {Prior} {Information} by {Iteratively} {Reweighted} {Least}-{Squares}},
	volume = {57},
	issn = {1053-587X, 1941-0476},
	url = {http://ieeexplore.ieee.org/document/4799125/},
	doi = {10.1109/TSP.2009.2016889},
	abstract = {Iteratively reweighted least-squares (IRLS) algorithms have been successfully used in compressive sensing to reconstruct sparse signals from incomplete linear measurements taken in nonsparse domains. The underlying optimization problem corresponds to ﬁnding the vector that solves the minimization while explaining the measurements, and IRLS allows to easily control the used value of , with effect on the number of required measurements. In this paper, we propose a weighting strategy in the reconstruction method based on IRLS in order to add prior information on the support of the sparse domain. Our simulation results show that the use of prior knowledge about positions of at least some of the nonzero coefﬁcients in the sparse domain leads to a reduction in the number of linear measurements required for unambiguous reconstruction. This reduction occurs for all values of , so that a further reduction can be achieved by decreasing and using prior information. The proposed weighting scheme also reduces the computational complexity with respect to the IRLS with no prior information, both in terms of number of iterations and computation time.},
	language = {en},
	number = {6},
	urldate = {2020-03-30},
	journal = {IEEE Transactions on Signal Processing},
	author = {Miosso, C.J. and von Borries, R. and Argaez, M. and Velazquez, L. and Quintero, C. and Potes, C.M.},
	month = jun,
	year = {2009},
	pages = {2424--2431}
}

@inproceedings{miosso_compressive_2009-1,
	address = {Pacific Grove, CA, USA},
	title = {Compressive sensing method for improved reconstruction of gradient-sparse magnetic resonance images},
	isbn = {978-1-4244-5825-7},
	url = {http://ieeexplore.ieee.org/document/5469970/},
	doi = {10.1109/ACSSC.2009.5469970},
	abstract = {We propose a compressive sensing method for reconstructing gradient-sparse magnetic resonance (MR) images based on the pre-ﬁltering of the input signals in the k-space. A set of ﬁltered versions of the image is reconstructed using the available k-space samples, and a ﬁnal reconstruction stage generates the desired image from the ﬁltered versions. Our experiments, conducted over real MR images and angiograms, show that the proposed method improves the reconstruction over the total-variation minimization, in terms of signal-to-noise ratio and computation time. The proposed method is particularly appropriate for computing MR angiograms, which are typically sparse under the ﬁnite-differences operation.},
	language = {en},
	urldate = {2020-03-30},
	booktitle = {2009 {Conference} {Record} of the {Forty}-{Third} {Asilomar} {Conference} on {Signals}, {Systems} and {Computers}},
	publisher = {IEEE},
	author = {Miosso, C. J. and von Borries, R. and Pierluissi, J. H.},
	year = {2009},
	pages = {799--806}
}

@article{lundervold_overview_2019,
	title = {An overview of deep learning in medical imaging focusing on {MRI}},
	volume = {29},
	issn = {09393889},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0939388918301181},
	doi = {10.1016/j.zemedi.2018.11.002},
	abstract = {What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artiﬁcial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding ﬁeld we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI.},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Zeitschrift für Medizinische Physik},
	author = {Lundervold, Alexander Selvikvåg and Lundervold, Arvid},
	month = may,
	year = {2019},
	pages = {102--127},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/IV3X7GWQ/Lundervold and Lundervold - 2019 - An overview of deep learning in medical imaging fo.pdf:application/pdf}
}

@article{lustig_sparse_2007,
	title = {Sparse {MRI}: {The} application of compressed sensing for rapid {MR} imaging},
	volume = {58},
	issn = {07403194, 15222594},
	shorttitle = {Sparse {MRI}},
	url = {http://doi.wiley.com/10.1002/mrm.21391},
	doi = {10.1002/mrm.21391},
	language = {en},
	number = {6},
	urldate = {2020-06-24},
	journal = {Magnetic Resonance in Medicine},
	author = {Lustig, Michael and Donoho, David and Pauly, John M.},
	month = dec,
	year = {2007},
	pages = {1182--1195},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/RUZP7JLJ/Lustig et al. - 2007 - Sparse MRI The application of compressed sensing .pdf:application/pdf}
}

@article{liang_deep_2019,
	title = {Deep {MRI} {Reconstruction}: {Unrolled} {Optimization} {Algorithms} {Meet} {Neural} {Networks}},
	shorttitle = {Deep {MRI} {Reconstruction}},
	url = {http://arxiv.org/abs/1907.11711},
	abstract = {Image reconstruction from undersampled k-space data has been playing an important role for fast MRI. Recently, deep learning has demonstrated tremendous success in various fields and also shown potential to significantly speed up MR reconstruction with reduced measurements. This article gives an overview of deep learning-based image reconstruction methods for MRI. Three types of deep learning-based approaches are reviewed, the data-driven, model-driven and integrated approaches. The main structure of each network in three approaches is explained and the analysis of common parts of reviewed networks and differences in-between are highlighted. Based on the review, a number of signal processing issues are discussed for maximizing the potential of deep reconstruction for fast MRI. the discussion may facilitate further development of "optimal" network and performance analysis from a theoretical point of view.},
	urldate = {2020-06-24},
	journal = {arXiv:1907.11711 [physics, stat]},
	author = {Liang, Dong and Cheng, Jing and Ke, Ziwen and Ying, Leslie},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.11711},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Signal Processing, Physics - Medical Physics},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/3L9QKFPX/Liang et al. - 2019 - Deep MRI Reconstruction Unrolled Optimization Alg.pdf:application/pdf}
}

@article{liang_deep_2020,
	title = {Deep {Magnetic} {Resonance} {Image} {Reconstruction}: {Inverse} {Problems} {Meet} {Neural} {Networks}},
	volume = {37},
	issn = {1053-5888, 1558-0792},
	shorttitle = {Deep {Magnetic} {Resonance} {Image} {Reconstruction}},
	url = {https://ieeexplore.ieee.org/document/8962949/},
	doi = {10.1109/MSP.2019.2950557},
	number = {1},
	urldate = {2020-06-24},
	journal = {IEEE Signal Processing Magazine},
	author = {Liang, Dong and Cheng, Jing and Ke, Ziwen and Ying, Leslie},
	month = jan,
	year = {2020},
	pages = {141--151}
}

@article{zhang_review_2020,
	title = {A {Review} on {Deep} {Learning} in {Medical} {Image} {Reconstruction}},
	volume = {8},
	issn = {2194-668X, 2194-6698},
	url = {http://link.springer.com/10.1007/s40305-019-00287-4},
	doi = {10.1007/s40305-019-00287-4},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Journal of the Operations Research Society of China},
	author = {Zhang, Hai-Miao and Dong, Bin},
	month = jun,
	year = {2020},
	pages = {311--340},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/Q25KULJ7/Zhang and Dong - 2020 - A Review on Deep Learning in Medical Image Reconst.pdf:application/pdf}
}

@incollection{mardani_neural_2018,
	title = {Neural {Proximal} {Gradient} {Descent} for {Compressive} {Imaging}},
	url = {http://papers.nips.cc/paper/8166-neural-proximal-gradient-descent-for-compressive-imaging.pdf},
	urldate = {2020-06-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Mardani, Morteza and Sun, Qingyun and Donoho, David and Papyan, Vardan and Monajemi, Hatef and Vasanawala, Shreyas and Pauly, John},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {9573--9583},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/J8EUUZXS/Mardani et al. - 2018 - Neural Proximal Gradient Descent for Compressive I.pdf:application/pdf}
}

@article{mardani_deep_2019,
	title = {Deep {Generative} {Adversarial} {Neural} {Networks} for {Compressive} {Sensing} {MRI}},
	volume = {38},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/8417964/},
	doi = {10.1109/TMI.2018.2858752},
	abstract = {Undersampled magnetic resonance image (MRI) reconstruction is typically an ill-posed linear inverse task. The time and resource intensive computations require trade offs between accuracy and speed. In addition, state-of-the-art compressed sensing (CS) analytics are not cognizant of the image diagnostic quality. To address these challenges, we propose a novel CS framework that uses generative adversarial networks (GAN) to model the (low-dimensional) manifold of high-quality MR images. Leveraging a mixture of least-squares (LS) GANs and pixel-wise 1/ 2 cost, a deep residual network with skip connections is trained as the generator that learns to remove the aliasing artifacts by projecting onto the image manifold. The LSGAN learns the texture details, while the 1/ 2 cost suppresses high-frequency noise. A discriminator network, which is a multilayer convolutional neural network (CNN), plays the role of a perceptual cost that is then jointly trained based on high quality MR images to score the quality of retrieved images. In the operational phase, an initial aliased estimate (e.g., simply obtained by zero-ﬁlling) is propagated into the trained generator to output the desired reconstruction. This demands very low computational overhead. Extensive evaluations are performed on a large contrast-enhanced MR dataset of pediatric patients. Images rated by expert radiologists corroborate that GANCS retrieves higher quality images with improved ﬁne texture details compared with conventional Wavelet-based and dictionary-learning based CS schemes as well as with deeplearning based schemes using pixel-wise training. In addition, it offers reconstruction times of under a few milliseconds, which is two orders of magnitude faster than current state-of-the-art CS-MRI schemes.},
	language = {en},
	number = {1},
	urldate = {2020-06-26},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Mardani, Morteza and Gong, Enhao and Cheng, Joseph Y. and Vasanawala, Shreyas S. and Zaharchuk, Greg and Xing, Lei and Pauly, John M.},
	month = jan,
	year = {2019},
	pages = {167--179},
	file = {Accepted Version:/home/gabrielziegler/Zotero/storage/26PF7TBN/Mardani et al. - 2019 - Deep Generative Adversarial Neural Networks for Co.pdf:application/pdf}
}

@incollection{yang_deep_2016,
	title = {Deep {ADMM}-{Net} for {Compressive} {Sensing} {MRI}},
	url = {http://papers.nips.cc/paper/6406-deep-admm-net-for-compressive-sensing-mri.pdf},
	urldate = {2020-06-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {yang, yan and Sun, Jian and Li, Huibin and Xu, Zongben},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {10--18},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/8VZ2TD38/yang et al. - 2016 - Deep ADMM-Net for Compressive Sensing MRI.pdf:application/pdf}
}

@article{makropoulos_review_2018,
	title = {A review on automatic fetal and neonatal brain {MRI} segmentation},
	volume = {170},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917305451},
	doi = {10.1016/j.neuroimage.2017.06.074},
	abstract = {In recent years, a variety of segmentation methods have been proposed for automatic delineation of the fetal and neonatal brain MRI. These methods aim to deﬁne regions of interest of diﬀerent granularity: brain, tissue types or more localised structures. Diﬀerent methodologies have been applied for this segmentation task and can be classiﬁed into unsupervised, parametric, classiﬁcation, atlas fusion and deformable models. Brain atlases are commonly utilised as training data in the segmentation process. Challenges relating to the image acquisition, the rapid brain development as well as the limited availability of imaging data however hinder this segmentation task. In this paper, we review methods adopted for the perinatal brain and categorise them according to the target population, structures segmented and methodology. We outline diﬀerent methods proposed in the literature and discuss their major contributions. Diﬀerent approaches for the evaluation of the segmentation accuracy and benchmarks used for the segmentation quality are presented. We conclude this review with a discussion on shortcomings in the perinatal domain and possible future directions.},
	language = {en},
	urldate = {2020-06-26},
	journal = {NeuroImage},
	author = {Makropoulos, Antonios and Counsell, Serena J. and Rueckert, Daniel},
	month = apr,
	year = {2018},
	pages = {231--248},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/69M86YJE/Makropoulos et al. - 2018 - A review on automatic fetal and neonatal brain MRI.pdf:application/pdf}
}

@article{donoho_compressed_2006,
	title = {Compressed sensing},
	volume = {52},
	issn = {0018-9448},
	url = {http://ieeexplore.ieee.org/document/1614066/},
	doi = {10.1109/TIT.2006.871582},
	abstract = {Suppose is an unknown vector in (a digital image or signal); we plan to measure general linear functionals of and then reconstruct. If is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure deﬁned here, the number of measurements can be dramatically smaller than the size . Thus, certain natural classes of images with pixels need only = ( 1 4 log5 2( )) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual pixel samples.},
	language = {en},
	number = {4},
	urldate = {2020-06-28},
	journal = {IEEE Transactions on Information Theory},
	author = {Donoho, D.L.},
	month = apr,
	year = {2006},
	pages = {1289--1306}
}

@article{kabanikhin_definitions_2008,
	title = {Definitions and examples of inverse and ill-posed problems},
	volume = {16},
	issn = {0928-0219, 1569-3945},
	url = {https://www.degruyter.com/view/j/jiip.2008.16.issue-4/jiip.2008.019/jiip.2008.019.xml},
	doi = {10.1515/JIIP.2008.019},
	abstract = {The terms “inverse problems” and “ill-posed problems” have been steadily and surely gaining popularity in modern science since the middle of the 20th century. A little more than ﬁfty years of studying problems of this kind have shown that a great number of problems from various branches of classical mathematics (computational algebra, differential and integral equations, partial differential equations, functional analysis) can be classiﬁed as inverse or ill-posed, and they are among the most complicated ones (since they are unstable and usually nonlinear). At the same time, inverse and ill-posed problems began to be studied and applied systematically in physics, geophysics, medicine, astronomy, and all other areas of knowledge where mathematical methods are used. The reason is that solutions to inverse problems describe important properties of media under study, such as density and velocity of wave propagation, elasticity parameters, conductivity, dielectric permittivity and magnetic permeability, and properties and location of inhomogeneities in inaccessible areas, etc.},
	language = {en},
	number = {4},
	urldate = {2020-06-29},
	journal = {Journal of Inverse and Ill-posed Problems},
	author = {Kabanikhin, S. I.},
	month = jan,
	year = {2008}
}

@article{radford_unsupervised_2016,
	title = {Unsupervised {Representation} {Learning} with {Deep} {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1511.06434},
	abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
	urldate = {2020-07-03},
	journal = {arXiv:1511.06434 [cs]},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	month = jan,
	year = {2016},
	note = {arXiv: 1511.06434},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/9XRY5RLP/Radford et al. - 2016 - Unsupervised Representation Learning with Deep Con.pdf:application/pdf}
}

@incollection{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Nets}},
	url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
	urldate = {2020-07-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {2672--2680},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/EW979R6X/Goodfellow et al. - 2014 - Generative Adversarial Nets.pdf:application/pdf}
}

@article{bryan_introduction_nodate,
	title = {Introduction to the {Science} of {Medical} {Imaging}},
	language = {en},
	author = {Bryan, R Nick},
	pages = {336}
}

@article{miosso_compressive_2009-2,
	title = {Compressive {Sensing} {Reconstruction} {With} {Prior} {Information} by {Iteratively} {Reweighted} {Least}-{Squares}},
	volume = {57},
	issn = {1053-587X, 1941-0476},
	url = {http://ieeexplore.ieee.org/document/4799125/},
	doi = {10.1109/TSP.2009.2016889},
	abstract = {Iteratively reweighted least-squares (IRLS) algorithms have been successfully used in compressive sensing to reconstruct sparse signals from incomplete linear measurements taken in nonsparse domains. The underlying optimization problem corresponds to ﬁnding the vector that solves the minimization while explaining the measurements, and IRLS allows to easily control the used value of , with effect on the number of required measurements. In this paper, we propose a weighting strategy in the reconstruction method based on IRLS in order to add prior information on the support of the sparse domain. Our simulation results show that the use of prior knowledge about positions of at least some of the nonzero coefﬁcients in the sparse domain leads to a reduction in the number of linear measurements required for unambiguous reconstruction. This reduction occurs for all values of , so that a further reduction can be achieved by decreasing and using prior information. The proposed weighting scheme also reduces the computational complexity with respect to the IRLS with no prior information, both in terms of number of iterations and computation time.},
	language = {en},
	number = {6},
	urldate = {2020-03-30},
	journal = {IEEE Transactions on Signal Processing},
	author = {Miosso, C.J. and von Borries, R. and Argaez, M. and Velazquez, L. and Quintero, C. and Potes, C.M.},
	month = jun,
	year = {2009},
	pages = {2424--2431}
}

@inproceedings{miosso_compressive_2009-3,
	address = {Pacific Grove, CA, USA},
	title = {Compressive sensing method for improved reconstruction of gradient-sparse magnetic resonance images},
	isbn = {978-1-4244-5825-7},
	url = {http://ieeexplore.ieee.org/document/5469970/},
	doi = {10.1109/ACSSC.2009.5469970},
	abstract = {We propose a compressive sensing method for reconstructing gradient-sparse magnetic resonance (MR) images based on the pre-ﬁltering of the input signals in the k-space. A set of ﬁltered versions of the image is reconstructed using the available k-space samples, and a ﬁnal reconstruction stage generates the desired image from the ﬁltered versions. Our experiments, conducted over real MR images and angiograms, show that the proposed method improves the reconstruction over the total-variation minimization, in terms of signal-to-noise ratio and computation time. The proposed method is particularly appropriate for computing MR angiograms, which are typically sparse under the ﬁnite-differences operation.},
	language = {en},
	urldate = {2020-03-30},
	booktitle = {2009 {Conference} {Record} of the {Forty}-{Third} {Asilomar} {Conference} on {Signals}, {Systems} and {Computers}},
	publisher = {IEEE},
	author = {Miosso, C. J. and von Borries, R. and Pierluissi, J. H.},
	year = {2009},
	pages = {799--806}
}

@article{lundervold_overview_2019-1,
	title = {An overview of deep learning in medical imaging focusing on {MRI}},
	volume = {29},
	issn = {09393889},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0939388918301181},
	doi = {10.1016/j.zemedi.2018.11.002},
	abstract = {What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artiﬁcial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding ﬁeld we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI.},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Zeitschrift für Medizinische Physik},
	author = {Lundervold, Alexander Selvikvåg and Lundervold, Arvid},
	month = may,
	year = {2019},
	pages = {102--127}
}

@article{lustig_sparse_2007-1,
	title = {Sparse {MRI}: {The} application of compressed sensing for rapid {MR} imaging},
	volume = {58},
	issn = {07403194, 15222594},
	shorttitle = {Sparse {MRI}},
	url = {http://doi.wiley.com/10.1002/mrm.21391},
	doi = {10.1002/mrm.21391},
	language = {en},
	number = {6},
	urldate = {2020-06-24},
	journal = {Magnetic Resonance in Medicine},
	author = {Lustig, Michael and Donoho, David and Pauly, John M.},
	month = dec,
	year = {2007},
	pages = {1182--1195}
}

@article{liang_deep_2019-1,
	title = {Deep {MRI} {Reconstruction}: {Unrolled} {Optimization} {Algorithms} {Meet} {Neural} {Networks}},
	shorttitle = {Deep {MRI} {Reconstruction}},
	url = {http://arxiv.org/abs/1907.11711},
	abstract = {Image reconstruction from undersampled k-space data has been playing an important role for fast MRI. Recently, deep learning has demonstrated tremendous success in various fields and also shown potential to significantly speed up MR reconstruction with reduced measurements. This article gives an overview of deep learning-based image reconstruction methods for MRI. Three types of deep learning-based approaches are reviewed, the data-driven, model-driven and integrated approaches. The main structure of each network in three approaches is explained and the analysis of common parts of reviewed networks and differences in-between are highlighted. Based on the review, a number of signal processing issues are discussed for maximizing the potential of deep reconstruction for fast MRI. the discussion may facilitate further development of "optimal" network and performance analysis from a theoretical point of view.},
	urldate = {2020-06-24},
	journal = {arXiv:1907.11711 [physics, stat]},
	author = {Liang, Dong and Cheng, Jing and Ke, Ziwen and Ying, Leslie},
	month = jul,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Signal Processing, Physics - Medical Physics}
}

@article{liang_deep_2020-1,
	title = {Deep {Magnetic} {Resonance} {Image} {Reconstruction}: {Inverse} {Problems} {Meet} {Neural} {Networks}},
	volume = {37},
	issn = {1053-5888, 1558-0792},
	shorttitle = {Deep {Magnetic} {Resonance} {Image} {Reconstruction}},
	url = {https://ieeexplore.ieee.org/document/8962949/},
	doi = {10.1109/MSP.2019.2950557},
	number = {1},
	urldate = {2020-06-24},
	journal = {IEEE Signal Processing Magazine},
	author = {Liang, Dong and Cheng, Jing and Ke, Ziwen and Ying, Leslie},
	month = jan,
	year = {2020},
	pages = {141--151}
}

@article{zhang_review_2020-1,
	title = {A {Review} on {Deep} {Learning} in {Medical} {Image} {Reconstruction}},
	volume = {8},
	issn = {2194-668X, 2194-6698},
	url = {http://link.springer.com/10.1007/s40305-019-00287-4},
	doi = {10.1007/s40305-019-00287-4},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Journal of the Operations Research Society of China},
	author = {Zhang, Hai-Miao and Dong, Bin},
	month = jun,
	year = {2020},
	pages = {311--340}
}

@incollection{mardani_neural_2018-1,
	title = {Neural {Proximal} {Gradient} {Descent} for {Compressive} {Imaging}},
	url = {http://papers.nips.cc/paper/8166-neural-proximal-gradient-descent-for-compressive-imaging.pdf},
	urldate = {2020-06-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Mardani, Morteza and Sun, Qingyun and Donoho, David and Papyan, Vardan and Monajemi, Hatef and Vasanawala, Shreyas and Pauly, John},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {9573--9583}
}

@article{mardani_deep_2019-1,
	title = {Deep {Generative} {Adversarial} {Neural} {Networks} for {Compressive} {Sensing} {MRI}},
	volume = {38},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/8417964/},
	doi = {10.1109/TMI.2018.2858752},
	abstract = {Undersampled magnetic resonance image (MRI) reconstruction is typically an ill-posed linear inverse task. The time and resource intensive computations require trade offs between accuracy and speed. In addition, state-of-the-art compressed sensing (CS) analytics are not cognizant of the image diagnostic quality. To address these challenges, we propose a novel CS framework that uses generative adversarial networks (GAN) to model the (low-dimensional) manifold of high-quality MR images. Leveraging a mixture of least-squares (LS) GANs and pixel-wise 1/ 2 cost, a deep residual network with skip connections is trained as the generator that learns to remove the aliasing artifacts by projecting onto the image manifold. The LSGAN learns the texture details, while the 1/ 2 cost suppresses high-frequency noise. A discriminator network, which is a multilayer convolutional neural network (CNN), plays the role of a perceptual cost that is then jointly trained based on high quality MR images to score the quality of retrieved images. In the operational phase, an initial aliased estimate (e.g., simply obtained by zero-ﬁlling) is propagated into the trained generator to output the desired reconstruction. This demands very low computational overhead. Extensive evaluations are performed on a large contrast-enhanced MR dataset of pediatric patients. Images rated by expert radiologists corroborate that GANCS retrieves higher quality images with improved ﬁne texture details compared with conventional Wavelet-based and dictionary-learning based CS schemes as well as with deeplearning based schemes using pixel-wise training. In addition, it offers reconstruction times of under a few milliseconds, which is two orders of magnitude faster than current state-of-the-art CS-MRI schemes.},
	language = {en},
	number = {1},
	urldate = {2020-06-26},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Mardani, Morteza and Gong, Enhao and Cheng, Joseph Y. and Vasanawala, Shreyas S. and Zaharchuk, Greg and Xing, Lei and Pauly, John M.},
	month = jan,
	year = {2019},
	pages = {167--179}
}

@incollection{yang_deep_2016-1,
	title = {Deep {ADMM}-{Net} for {Compressive} {Sensing} {MRI}},
	url = {http://papers.nips.cc/paper/6406-deep-admm-net-for-compressive-sensing-mri.pdf},
	urldate = {2020-06-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {yang, yan and Sun, Jian and Li, Huibin and Xu, Zongben},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {10--18}
}

@article{makropoulos_review_2018-1,
	title = {A review on automatic fetal and neonatal brain {MRI} segmentation},
	volume = {170},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917305451},
	doi = {10.1016/j.neuroimage.2017.06.074},
	abstract = {In recent years, a variety of segmentation methods have been proposed for automatic delineation of the fetal and neonatal brain MRI. These methods aim to deﬁne regions of interest of diﬀerent granularity: brain, tissue types or more localised structures. Diﬀerent methodologies have been applied for this segmentation task and can be classiﬁed into unsupervised, parametric, classiﬁcation, atlas fusion and deformable models. Brain atlases are commonly utilised as training data in the segmentation process. Challenges relating to the image acquisition, the rapid brain development as well as the limited availability of imaging data however hinder this segmentation task. In this paper, we review methods adopted for the perinatal brain and categorise them according to the target population, structures segmented and methodology. We outline diﬀerent methods proposed in the literature and discuss their major contributions. Diﬀerent approaches for the evaluation of the segmentation accuracy and benchmarks used for the segmentation quality are presented. We conclude this review with a discussion on shortcomings in the perinatal domain and possible future directions.},
	language = {en},
	urldate = {2020-06-26},
	journal = {NeuroImage},
	author = {Makropoulos, Antonios and Counsell, Serena J. and Rueckert, Daniel},
	month = apr,
	year = {2018},
	pages = {231--248}
}

@article{donoho_compressed_2006-1,
	title = {Compressed sensing},
	volume = {52},
	issn = {0018-9448},
	url = {http://ieeexplore.ieee.org/document/1614066/},
	doi = {10.1109/TIT.2006.871582},
	abstract = {Suppose is an unknown vector in (a digital image or signal); we plan to measure general linear functionals of and then reconstruct. If is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure deﬁned here, the number of measurements can be dramatically smaller than the size . Thus, certain natural classes of images with pixels need only = ( 1 4 log5 2( )) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual pixel samples.},
	language = {en},
	number = {4},
	urldate = {2020-06-28},
	journal = {IEEE Transactions on Information Theory},
	author = {Donoho, D.L.},
	month = apr,
	year = {2006},
	pages = {1289--1306}
}

@article{kabanikhin_definitions_2008-1,
	title = {Definitions and examples of inverse and ill-posed problems},
	volume = {16},
	issn = {0928-0219, 1569-3945},
	url = {https://www.degruyter.com/view/j/jiip.2008.16.issue-4/jiip.2008.019/jiip.2008.019.xml},
	doi = {10.1515/JIIP.2008.019},
	abstract = {The terms “inverse problems” and “ill-posed problems” have been steadily and surely gaining popularity in modern science since the middle of the 20th century. A little more than ﬁfty years of studying problems of this kind have shown that a great number of problems from various branches of classical mathematics (computational algebra, differential and integral equations, partial differential equations, functional analysis) can be classiﬁed as inverse or ill-posed, and they are among the most complicated ones (since they are unstable and usually nonlinear). At the same time, inverse and ill-posed problems began to be studied and applied systematically in physics, geophysics, medicine, astronomy, and all other areas of knowledge where mathematical methods are used. The reason is that solutions to inverse problems describe important properties of media under study, such as density and velocity of wave propagation, elasticity parameters, conductivity, dielectric permittivity and magnetic permeability, and properties and location of inhomogeneities in inaccessible areas, etc.},
	language = {en},
	number = {4},
	urldate = {2020-06-29},
	journal = {Journal of Inverse and Ill-posed Problems},
	author = {Kabanikhin, S. I.},
	month = jan,
	year = {2008}
}

@article{radford_unsupervised_2016-1,
	title = {Unsupervised {Representation} {Learning} with {Deep} {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1511.06434},
	abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
	urldate = {2020-07-03},
	journal = {arXiv:1511.06434 [cs]},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	month = jan,
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition}
}

@incollection{goodfellow_generative_2014-1,
	title = {Generative {Adversarial} {Nets}},
	url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
	urldate = {2020-07-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {2672--2680}
}

@article{bryan_introduction_nodate-1,
	title = {Introduction to the {Science} of {Medical} {Imaging}},
	language = {en},
	author = {Bryan, R Nick},
	pages = {336}
}

@phdthesis{miosso_cristiano_jacques_compressive_nodate,
	type = {{PhD} {Thesis}},
	title = {Compressive {Sensing} with {Prior} {Information} {Applied} to {Magnetic} {Resonance} {Imaging}},
	school = {Department of Electrical and Computer Engineering, University of Texas at El Paso (UTEP)},
	author = {Miosso, Cristiano Jacques},
	file = {miosso_phd.pdf:/home/gabrielziegler/Zotero/storage/T8QDEJDP/miosso_phd.pdf:application/pdf}
}

@phdthesis{miosso_cristiano_jacques_compressive_nodate-1,
	type = {{PhD} {Thesis}},
	title = {Compressive {Sensing} with {Prior} {Information} {Applied} to {Magnetic} {Resonance} {Imaging}},
	school = {Department of Electrical and Computer Engineering, University of Texas at El Paso (UTEP)},
	author = {Miosso, Cristiano Jacques},
	file = {miosso_phd.pdf:/home/gabrielziegler/Zotero/storage/UVIK74EM/miosso_phd.pdf:application/pdf}
}

@article{miosso_compressive_2009-4,
	title = {Compressive {Sensing} {Reconstruction} {With} {Prior} {Information} by {Iteratively} {Reweighted} {Least}-{Squares}},
	volume = {57},
	issn = {1053-587X, 1941-0476},
	url = {http://ieeexplore.ieee.org/document/4799125/},
	doi = {10.1109/TSP.2009.2016889},
	abstract = {Iteratively reweighted least-squares (IRLS) algorithms have been successfully used in compressive sensing to reconstruct sparse signals from incomplete linear measurements taken in nonsparse domains. The underlying optimization problem corresponds to ﬁnding the vector that solves the minimization while explaining the measurements, and IRLS allows to easily control the used value of , with effect on the number of required measurements. In this paper, we propose a weighting strategy in the reconstruction method based on IRLS in order to add prior information on the support of the sparse domain. Our simulation results show that the use of prior knowledge about positions of at least some of the nonzero coefﬁcients in the sparse domain leads to a reduction in the number of linear measurements required for unambiguous reconstruction. This reduction occurs for all values of , so that a further reduction can be achieved by decreasing and using prior information. The proposed weighting scheme also reduces the computational complexity with respect to the IRLS with no prior information, both in terms of number of iterations and computation time.},
	language = {en},
	number = {6},
	urldate = {2020-03-30},
	journal = {IEEE Transactions on Signal Processing},
	author = {Miosso, C.J. and von Borries, R. and Argaez, M. and Velazquez, L. and Quintero, C. and Potes, C.M.},
	month = jun,
	year = {2009},
	pages = {2424--2431},
	file = {Miosso et al. - 2009 - Compressive Sensing Reconstruction With Prior Info.pdf:/home/gabrielziegler/Zotero/storage/HT2FZJKR/Miosso et al. - 2009 - Compressive Sensing Reconstruction With Prior Info.pdf:application/pdf}
}

@inproceedings{miosso_compressive_2009-5,
	address = {Pacific Grove, CA, USA},
	title = {Compressive sensing method for improved reconstruction of gradient-sparse magnetic resonance images},
	isbn = {978-1-4244-5825-7},
	url = {http://ieeexplore.ieee.org/document/5469970/},
	doi = {10.1109/ACSSC.2009.5469970},
	abstract = {We propose a compressive sensing method for reconstructing gradient-sparse magnetic resonance (MR) images based on the pre-ﬁltering of the input signals in the k-space. A set of ﬁltered versions of the image is reconstructed using the available k-space samples, and a ﬁnal reconstruction stage generates the desired image from the ﬁltered versions. Our experiments, conducted over real MR images and angiograms, show that the proposed method improves the reconstruction over the total-variation minimization, in terms of signal-to-noise ratio and computation time. The proposed method is particularly appropriate for computing MR angiograms, which are typically sparse under the ﬁnite-differences operation.},
	language = {en},
	urldate = {2020-03-30},
	booktitle = {2009 {Conference} {Record} of the {Forty}-{Third} {Asilomar} {Conference} on {Signals}, {Systems} and {Computers}},
	publisher = {IEEE},
	author = {Miosso, C. J. and von Borries, R. and Pierluissi, J. H.},
	year = {2009},
	pages = {799--806},
	file = {Miosso et al. - 2009 - Compressive sensing method for improved reconstruc.pdf:/home/gabrielziegler/Zotero/storage/IJI7GDIF/Miosso et al. - 2009 - Compressive sensing method for improved reconstruc.pdf:application/pdf}
}

@article{lundervold_overview_2019-2,
	title = {An overview of deep learning in medical imaging focusing on {MRI}},
	volume = {29},
	issn = {09393889},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0939388918301181},
	doi = {10.1016/j.zemedi.2018.11.002},
	abstract = {What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artiﬁcial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding ﬁeld we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI.},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Zeitschrift für Medizinische Physik},
	author = {Lundervold, Alexander Selvikvåg and Lundervold, Arvid},
	month = may,
	year = {2019},
	pages = {102--127},
	file = {Lundervold and Lundervold - 2019 - An overview of deep learning in medical imaging fo.pdf:/home/gabrielziegler/Zotero/storage/5VWIHJVM/Lundervold and Lundervold - 2019 - An overview of deep learning in medical imaging fo.pdf:application/pdf}
}

@article{lustig_sparse_2007-2,
	title = {Sparse {MRI}: {The} application of compressed sensing for rapid {MR} imaging},
	volume = {58},
	issn = {07403194, 15222594},
	shorttitle = {Sparse {MRI}},
	url = {http://doi.wiley.com/10.1002/mrm.21391},
	doi = {10.1002/mrm.21391},
	language = {en},
	number = {6},
	urldate = {2020-06-24},
	journal = {Magnetic Resonance in Medicine},
	author = {Lustig, Michael and Donoho, David and Pauly, John M.},
	month = dec,
	year = {2007},
	pages = {1182--1195},
	file = {Lustig et al. - 2007 - Sparse MRI The application of compressed sensing .pdf:/home/gabrielziegler/Zotero/storage/K7WCEBDX/Lustig et al. - 2007 - Sparse MRI The application of compressed sensing .pdf:application/pdf}
}

@article{liang_deep_2019-2,
	title = {Deep {MRI} {Reconstruction}: {Unrolled} {Optimization} {Algorithms} {Meet} {Neural} {Networks}},
	shorttitle = {Deep {MRI} {Reconstruction}},
	url = {http://arxiv.org/abs/1907.11711},
	abstract = {Image reconstruction from undersampled k-space data has been playing an important role for fast MRI. Recently, deep learning has demonstrated tremendous success in various fields and also shown potential to significantly speed up MR reconstruction with reduced measurements. This article gives an overview of deep learning-based image reconstruction methods for MRI. Three types of deep learning-based approaches are reviewed, the data-driven, model-driven and integrated approaches. The main structure of each network in three approaches is explained and the analysis of common parts of reviewed networks and differences in-between are highlighted. Based on the review, a number of signal processing issues are discussed for maximizing the potential of deep reconstruction for fast MRI. the discussion may facilitate further development of "optimal" network and performance analysis from a theoretical point of view.},
	urldate = {2020-06-24},
	journal = {arXiv:1907.11711 [physics, stat]},
	author = {Liang, Dong and Cheng, Jing and Ke, Ziwen and Ying, Leslie},
	month = jul,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Signal Processing, Physics - Medical Physics},
	file = {arXiv Fulltext PDF:/home/gabrielziegler/Zotero/storage/SV2X5SC8/Liang et al. - 2019 - Deep MRI Reconstruction Unrolled Optimization Alg.pdf:application/pdf;arXiv.org Snapshot:/home/gabrielziegler/Zotero/storage/ZB2LTGAZ/1907.html:text/html}
}

@article{zhang_review_2020-2,
	title = {A {Review} on {Deep} {Learning} in {Medical} {Image} {Reconstruction}},
	volume = {8},
	issn = {2194-668X, 2194-6698},
	url = {http://link.springer.com/10.1007/s40305-019-00287-4},
	doi = {10.1007/s40305-019-00287-4},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Journal of the Operations Research Society of China},
	author = {Zhang, Hai-Miao and Dong, Bin},
	month = jun,
	year = {2020},
	pages = {311--340},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/XTLEEKCM/Zhang and Dong - 2020 - A Review on Deep Learning in Medical Image Reconst.pdf:application/pdf}
}

@incollection{mardani_neural_2018-2,
	title = {Neural {Proximal} {Gradient} {Descent} for {Compressive} {Imaging}},
	url = {http://papers.nips.cc/paper/8166-neural-proximal-gradient-descent-for-compressive-imaging.pdf},
	urldate = {2020-06-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Mardani, Morteza and Sun, Qingyun and Donoho, David and Papyan, Vardan and Monajemi, Hatef and Vasanawala, Shreyas and Pauly, John},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {9573--9583},
	file = {NIPS Full Text PDF:/home/gabrielziegler/Zotero/storage/SCRCZG47/Mardani et al. - 2018 - Neural Proximal Gradient Descent for Compressive I.pdf:application/pdf;NIPS Snapshot:/home/gabrielziegler/Zotero/storage/Y4WRKAT2/8166-neural-proximal-gradient-descent-for-compressive-imaging.html:text/html}
}

@article{mardani_deep_2019-2,
	title = {Deep {Generative} {Adversarial} {Neural} {Networks} for {Compressive} {Sensing} {MRI}},
	volume = {38},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/8417964/},
	doi = {10.1109/TMI.2018.2858752},
	abstract = {Undersampled magnetic resonance image (MRI) reconstruction is typically an ill-posed linear inverse task. The time and resource intensive computations require trade offs between accuracy and speed. In addition, state-of-the-art compressed sensing (CS) analytics are not cognizant of the image diagnostic quality. To address these challenges, we propose a novel CS framework that uses generative adversarial networks (GAN) to model the (low-dimensional) manifold of high-quality MR images. Leveraging a mixture of least-squares (LS) GANs and pixel-wise 1/ 2 cost, a deep residual network with skip connections is trained as the generator that learns to remove the aliasing artifacts by projecting onto the image manifold. The LSGAN learns the texture details, while the 1/ 2 cost suppresses high-frequency noise. A discriminator network, which is a multilayer convolutional neural network (CNN), plays the role of a perceptual cost that is then jointly trained based on high quality MR images to score the quality of retrieved images. In the operational phase, an initial aliased estimate (e.g., simply obtained by zero-ﬁlling) is propagated into the trained generator to output the desired reconstruction. This demands very low computational overhead. Extensive evaluations are performed on a large contrast-enhanced MR dataset of pediatric patients. Images rated by expert radiologists corroborate that GANCS retrieves higher quality images with improved ﬁne texture details compared with conventional Wavelet-based and dictionary-learning based CS schemes as well as with deeplearning based schemes using pixel-wise training. In addition, it offers reconstruction times of under a few milliseconds, which is two orders of magnitude faster than current state-of-the-art CS-MRI schemes.},
	language = {en},
	number = {1},
	urldate = {2020-06-26},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Mardani, Morteza and Gong, Enhao and Cheng, Joseph Y. and Vasanawala, Shreyas S. and Zaharchuk, Greg and Xing, Lei and Pauly, John M.},
	month = jan,
	year = {2019},
	pages = {167--179},
	file = {Mardani et al. - 2019 - Deep Generative Adversarial Neural Networks for Co.pdf:/home/gabrielziegler/Zotero/storage/QJ5X4VH6/Mardani et al. - 2019 - Deep Generative Adversarial Neural Networks for Co.pdf:application/pdf}
}

@incollection{yang_deep_2016-2,
	title = {Deep {ADMM}-{Net} for {Compressive} {Sensing} {MRI}},
	url = {http://papers.nips.cc/paper/6406-deep-admm-net-for-compressive-sensing-mri.pdf},
	urldate = {2020-06-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {yang, yan and Sun, Jian and Li, Huibin and Xu, Zongben},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {10--18},
	file = {NIPS Full Text PDF:/home/gabrielziegler/Zotero/storage/HCRTT2SI/yang et al. - 2016 - Deep ADMM-Net for Compressive Sensing MRI.pdf:application/pdf;NIPS Snapshot:/home/gabrielziegler/Zotero/storage/ATV4HPWZ/6406-deep-admm-net-for-compressive-sensing-mri.html:text/html}
}

@article{makropoulos_review_2018-2,
	title = {A review on automatic fetal and neonatal brain {MRI} segmentation},
	volume = {170},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917305451},
	doi = {10.1016/j.neuroimage.2017.06.074},
	abstract = {In recent years, a variety of segmentation methods have been proposed for automatic delineation of the fetal and neonatal brain MRI. These methods aim to deﬁne regions of interest of diﬀerent granularity: brain, tissue types or more localised structures. Diﬀerent methodologies have been applied for this segmentation task and can be classiﬁed into unsupervised, parametric, classiﬁcation, atlas fusion and deformable models. Brain atlases are commonly utilised as training data in the segmentation process. Challenges relating to the image acquisition, the rapid brain development as well as the limited availability of imaging data however hinder this segmentation task. In this paper, we review methods adopted for the perinatal brain and categorise them according to the target population, structures segmented and methodology. We outline diﬀerent methods proposed in the literature and discuss their major contributions. Diﬀerent approaches for the evaluation of the segmentation accuracy and benchmarks used for the segmentation quality are presented. We conclude this review with a discussion on shortcomings in the perinatal domain and possible future directions.},
	language = {en},
	urldate = {2020-06-26},
	journal = {NeuroImage},
	author = {Makropoulos, Antonios and Counsell, Serena J. and Rueckert, Daniel},
	month = apr,
	year = {2018},
	pages = {231--248},
	file = {Makropoulos et al. - 2018 - A review on automatic fetal and neonatal brain MRI.pdf:/home/gabrielziegler/Zotero/storage/KLIT28QT/Makropoulos et al. - 2018 - A review on automatic fetal and neonatal brain MRI.pdf:application/pdf}
}

@article{donoho_compressed_2006-2,
	title = {Compressed sensing},
	volume = {52},
	issn = {0018-9448},
	url = {http://ieeexplore.ieee.org/document/1614066/},
	doi = {10.1109/TIT.2006.871582},
	abstract = {Suppose is an unknown vector in (a digital image or signal); we plan to measure general linear functionals of and then reconstruct. If is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure deﬁned here, the number of measurements can be dramatically smaller than the size . Thus, certain natural classes of images with pixels need only = ( 1 4 log5 2( )) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual pixel samples.},
	language = {en},
	number = {4},
	urldate = {2020-06-28},
	journal = {IEEE Transactions on Information Theory},
	author = {Donoho, D.L.},
	month = apr,
	year = {2006},
	pages = {1289--1306},
	file = {Donoho - 2006 - Compressed sensing.pdf:/home/gabrielziegler/Zotero/storage/T4Y59U8U/Donoho - 2006 - Compressed sensing.pdf:application/pdf}
}

@article{kabanikhin_definitions_2008-2,
	title = {Definitions and examples of inverse and ill-posed problems},
	volume = {16},
	issn = {0928-0219, 1569-3945},
	url = {https://www.degruyter.com/view/j/jiip.2008.16.issue-4/jiip.2008.019/jiip.2008.019.xml},
	doi = {10.1515/JIIP.2008.019},
	abstract = {The terms “inverse problems” and “ill-posed problems” have been steadily and surely gaining popularity in modern science since the middle of the 20th century. A little more than ﬁfty years of studying problems of this kind have shown that a great number of problems from various branches of classical mathematics (computational algebra, differential and integral equations, partial differential equations, functional analysis) can be classiﬁed as inverse or ill-posed, and they are among the most complicated ones (since they are unstable and usually nonlinear). At the same time, inverse and ill-posed problems began to be studied and applied systematically in physics, geophysics, medicine, astronomy, and all other areas of knowledge where mathematical methods are used. The reason is that solutions to inverse problems describe important properties of media under study, such as density and velocity of wave propagation, elasticity parameters, conductivity, dielectric permittivity and magnetic permeability, and properties and location of inhomogeneities in inaccessible areas, etc.},
	language = {en},
	number = {4},
	urldate = {2020-06-29},
	journal = {Journal of Inverse and Ill-posed Problems},
	author = {Kabanikhin, S. I.},
	month = jan,
	year = {2008},
	file = {Kabanikhin - 2008 - Definitions and examples of inverse and ill-posed .pdf:/home/gabrielziegler/Zotero/storage/9LZBXJZC/Kabanikhin - 2008 - Definitions and examples of inverse and ill-posed .pdf:application/pdf}
}

@article{radford_unsupervised_2016-2,
	title = {Unsupervised {Representation} {Learning} with {Deep} {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1511.06434},
	abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
	urldate = {2020-07-03},
	journal = {arXiv:1511.06434 [cs]},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	month = jan,
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/gabrielziegler/Zotero/storage/DS8IVNUM/Radford et al. - 2016 - Unsupervised Representation Learning with Deep Con.pdf:application/pdf;arXiv.org Snapshot:/home/gabrielziegler/Zotero/storage/RP9PJCL8/1511.html:text/html}
}

@incollection{goodfellow_generative_2014-2,
	title = {Generative {Adversarial} {Nets}},
	url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
	urldate = {2020-07-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {2672--2680},
	file = {NIPS Full Text PDF:/home/gabrielziegler/Zotero/storage/HUVFA9GB/Goodfellow et al. - 2014 - Generative Adversarial Nets.pdf:application/pdf;NIPS Snapshot:/home/gabrielziegler/Zotero/storage/3N83L6CN/5423-generative-adversarial-nets.html:text/html}
}

@article{bryan_introduction_nodate-2,
	title = {Introduction to the {Science} of {Medical} {Imaging}},
	language = {en},
	author = {Bryan, R Nick},
	pages = {336},
	file = {Bryan - Introduction to the Science of Medical Imaging.pdf:/home/gabrielziegler/Zotero/storage/VHVQP73I/Bryan - Introduction to the Science of Medical Imaging.pdf:application/pdf}
}

@phdthesis{miosso_compressive_nodate,
	type = {{PhD} {Thesis}},
	title = {Compressive {Sensing} with {Prior} {Information} {Applied} to {Magnetic} {Resonance} {Imaging}},
	school = {Department of Electrical and Computer Engineering, University of Texas at El Paso (UTEP)},
	author = {Miosso, Cristiano Jacques},
	file = {miosso_phd.pdf:/home/gabrielziegler/Zotero/storage/UUIWYN9K/miosso_phd.pdf:application/pdf}
}

@article{dias_metodos_nodate,
	title = {Métodos para {Reconstrução} de {Imagens} de {Tomografia} da {Coroa} {Solar} {Baseados} em},
	language = {pt},
	author = {Dias, Daniele},
	pages = {82},
	file = {Dias - Métodos para Reconstrução de Imagens de Tomografia.pdf:/home/gabrielziegler/Zotero/storage/HVWM76WR/Dias - Métodos para Reconstrução de Imagens de Tomografia.pdf:application/pdf}
}

@inproceedings{devlin_bert_2019,
	address = {Minneapolis, Minnesota},
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {https://www.aclweb.org/anthology/N19-1423},
	doi = {10.18653/v1/N19-1423},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2020-07-28},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = jun,
	year = {2019},
	pages = {4171--4186},
	file = {Full Text PDF:/home/gabrielziegler/Zotero/storage/C645MQ6Y/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf}
}

@article{wan_regularization_nodate,
	title = {Regularization of {Neural} {Networks} using {DropConnect}},
	abstract = {We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models.},
	language = {en},
	author = {Wan, Li and Zeiler, Matthew and Zhang, Sixin and {Yann LeCun}},
	pages = {12},
	file = {Wan et al. - Regularization of Neural Networks using DropConnec.pdf:/home/gabrielziegler/Zotero/storage/4BTAM5HN/Wan et al. - Regularization of Neural Networks using DropConnec.pdf:application/pdf}
}

@article{wan_regularization_nodate-1,
	title = {Regularization of {Neural} {Networks} using {DropConnect}},
	abstract = {We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models.},
	language = {en},
	journal = {ICML 2013},
	author = {Wan, Li and Zeiler, Matthew and Zhang, Sixin and LeCun, Yann and Fergus, Rob},
	pages = {12},
	file = {Wan et al. - Regularization of Neural Networks using DropConnec.pdf:/home/gabrielziegler/Zotero/storage/TL6JXVEZ/Wan et al. - Regularization of Neural Networks using DropConnec.pdf:application/pdf}
}

@inproceedings{kim_enhancing_2019,
	address = {Copenhagen Denmark},
	title = {Enhancing {VAEs} for collaborative filtering: flexible priors \& gating mechanisms},
	isbn = {978-1-4503-6243-6},
	shorttitle = {Enhancing {VAEs} for collaborative filtering},
	url = {https://dl.acm.org/doi/10.1145/3298689.3347015},
	doi = {10.1145/3298689.3347015},
	language = {en},
	urldate = {2020-07-28},
	booktitle = {Proceedings of the 13th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Kim, Daeryong and Suh, Bongwon},
	month = sep,
	year = {2019},
	pages = {403--407},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/WML5YN8A/Kim and Suh - 2019 - Enhancing VAEs for collaborative filtering flexib.pdf:application/pdf}
}

@book{patterson_deep_2017,
	address = {Beijing},
	title = {Deep {Learning}: {A} {Practitioner}'s {Approach}},
	isbn = {978-1-4919-1425-0},
	url = {https://www.safaribooksonline.com/library/view/deep-learning/9781491924570/},
	abstract = {Although interest in machine learning has reached a high point, lofty expectations often scuttle projects before they get very far. How can machine learning—especially deep neural networks—make a real difference in your organization? This hands-on guide not only provides the most practical information available on the subject, but also helps you get started building efficient deep learning networks. The authors provide theory on deep learning before introducing their open-source Deeplearning4j (DL4J) library for developing production-class workflows. Through real-world examples, you will learn methods and strategies for training deep network architectures and running deep learning workflows on Spark and Hadoop with DL4J.},
	publisher = {O'Reilly},
	author = {Patterson, Josh and Gibson, Adam},
	year = {2017},
	keywords = {01841 102 safari book numerical ai software development learn java tool},
	file = {Josh Patterson, Adam Gibson - Deep Learning_ A Practitioner’s Approach (2017, O’Reilly Media) - libgen.lc.pdf:/home/gabrielziegler/Zotero/storage/QJ825QMM/Josh Patterson, Adam Gibson - Deep Learning_ A Practitioner’s Approach (2017, O’Reilly Media) - libgen.lc.pdf:application/pdf}
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	file = {Yoshua Bengio, Ian Goodfellow - Deep learning (2016, The MIT Press).pdf:/home/gabrielziegler/Zotero/storage/CFQURPIU/Yoshua Bengio, Ian Goodfellow - Deep learning (2016, The MIT Press).pdf:application/pdf}
}

@misc{noauthor_top_nodate,
	title = {Top 100 {Piano} {Tabs} @ {911Tabs}},
	url = {https://www.911tabs.com/top/piano_tabs/},
	urldate = {2020-07-31},
	file = {Top 100 Piano Tabs @ 911Tabs:/home/gabrielziegler/Zotero/storage/QBGVRZVD/piano_tabs.html:text/html}
}

@article{oliveira_system_2017,
	title = {A {System} {Based} on {Artificial} {Neural} {Networks} for {Automatic} {Classification} of {Hydro}-generator {Stator} {Windings} {Partial} {Discharges}},
	volume = {16},
	issn = {2179-1074},
	url = {http://www.scielo.br/scielo.php?script=sci_arttext&pid=S2179-10742017000300628&nrm=iso},
	language = {en},
	journal = {Journal of Microwaves, Optoelectronics and Electromagnetic Applications},
	author = {Oliveira, Rodrigo M. S. de and , Ramon C. F. and Barros and Segundo, Adriano Paranhos and Zampolo, Ronaldo F. and Fonseca, Wellington and Dmitriev, Victor and Brasil, Fernando S.},
	year = {2017},
	note = {Publisher: scielo},
	pages = {628 -- 645}
}

@article{buduma_fundamentals_nodate,
	title = {Fundamentals of {Deep} {Learning}},
	language = {en},
	author = {Buduma, Nikhil and Locascio, Nicholas},
	pages = {298}
}

@book{buduma_fundamentals_2017,
	edition = {1st},
	title = {Fundamentals of {Deep} {Learning}: {Designing} {Next}-{Generation} {Machine} {Intelligence} {Algorithms}},
	isbn = {1-4919-2561-2},
	publisher = {O’Reilly Media, Inc.},
	author = {Buduma, Nikhil and Locascio, Nicholas},
	year = {2017},
	file = {Buduma and Locascio - Fundamentals of Deep Learning.pdf:/home/gabrielziegler/Zotero/storage/JX43EYPU/Buduma and Locascio - Fundamentals of Deep Learning.pdf:application/pdf}
}

@article{rani_systematic_2018,
	title = {A {Systematic} {Review} of {Compressive} {Sensing}: {Concepts}, {Implementations} and {Applications}},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {A {Systematic} {Review} of {Compressive} {Sensing}},
	url = {http://ieeexplore.ieee.org/document/8260873/},
	doi = {10.1109/ACCESS.2018.2793851},
	abstract = {Compressive Sensing (CS) is a new sensing modality which compresses the signal being acquired at the time of sensing. Signals can have sparse or compressible representation either in original domain or in some transform domain. Relying on the sparsity of the signals, CS allows us to sample the signal at a rate much below the Nyquist sampling rate. Also, the varied reconstruction algorithms of CS can faithfully reconstruct the original signal back from fewer compressive measurements. This fact has stimulated research interest towards the use of CS in the several ﬁelds like magnetic resonance imaging, high speed video acquisition, ultrawideband (UWB) communication, etc. This survey paper reviews the basic theoretical concepts underlying CS. To bridge the gap between theory and practicality of CS, different CS acquisition strategies and reconstruction approaches are elaborated systematically in this paper. The major application areas where CS is currently being used are reviewed here. This paper also highlights some of the challenges and research directions in this ﬁeld.},
	language = {en},
	urldate = {2020-08-18},
	journal = {IEEE Access},
	author = {Rani, Meenu and Dhok, S. B. and Deshmukh, R. B.},
	year = {2018},
	pages = {4875--4894},
	file = {Rani et al. - 2018 - A Systematic Review of Compressive Sensing Concep.pdf:/home/gabrielziegler/Zotero/storage/7KS2MY84/Rani et al. - 2018 - A Systematic Review of Compressive Sensing Concep.pdf:application/pdf}
}

@article{ye_compressed_2019,
	title = {Compressed sensing {MRI}: a review from signal processing perspective},
	volume = {1},
	issn = {2524-4426},
	shorttitle = {Compressed sensing {MRI}},
	url = {https://bmcbiomedeng.biomedcentral.com/articles/10.1186/s42490-019-0006-z},
	doi = {10.1186/s42490-019-0006-z},
	abstract = {Magnetic resonance imaging (MRI) is an inherently slow imaging modality, since it acquires multi-dimensional kspace data through 1-D free induction decay or echo signals. This often limits the use of MRI, especially for high resolution or dynamic imaging. Accordingly, many investigators has developed various acceleration techniques to allow fast MR imaging. For the last two decades, one of the most important breakthroughs in this direction is the introduction of compressed sensing (CS) that allows accurate reconstruction from sparsely sampled k-space data. The recent FDA approval of compressed sensing products for clinical scans clearly reflect the maturity of this technology. Therefore, this paper reviews the basic idea of CS and how this technology have been evolved for various MR imaging problems.},
	language = {en},
	number = {1},
	urldate = {2020-08-18},
	journal = {BMC Biomedical Engineering},
	author = {Ye, Jong Chul},
	month = dec,
	year = {2019},
	pages = {8},
	file = {Ye - 2019 - Compressed sensing MRI a review from signal proce.pdf:/home/gabrielziegler/Zotero/storage/2S4TIBQB/Ye - 2019 - Compressed sensing MRI a review from signal proce.pdf:application/pdf}
}
