
@article{lundervold_overview_2019,
	title = {An overview of deep learning in medical imaging focusing on {MRI}},
	volume = {29},
	issn = {09393889},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0939388918301181},
	doi = {10.1016/j.zemedi.2018.11.002},
	abstract = {What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artiﬁcial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding ﬁeld we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI.},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Zeitschrift für Medizinische Physik},
	author = {Lundervold, Alexander Selvikvåg and Lundervold, Arvid},
	month = may,
	year = {2019},
	pages = {102--127},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/IV3X7GWQ/Lundervold and Lundervold - 2019 - An overview of deep learning in medical imaging fo.pdf:application/pdf}
}

@article{lustig_sparse_2007,
	title = {Sparse {MRI}: {The} application of compressed sensing for rapid {MR} imaging},
	volume = {58},
	issn = {07403194, 15222594},
	shorttitle = {Sparse {MRI}},
	url = {http://doi.wiley.com/10.1002/mrm.21391},
	doi = {10.1002/mrm.21391},
	language = {en},
	number = {6},
	urldate = {2020-06-24},
	journal = {Magnetic Resonance in Medicine},
	author = {Lustig, Michael and Donoho, David and Pauly, John M.},
	month = dec,
	year = {2007},
	pages = {1182--1195},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/RUZP7JLJ/Lustig et al. - 2007 - Sparse MRI The application of compressed sensing .pdf:application/pdf}
}

@article{zhang_review_2020,
	title = {A {Review} on {Deep} {Learning} in {Medical} {Image} {Reconstruction}},
	volume = {8},
	issn = {2194-668X, 2194-6698},
	url = {http://link.springer.com/10.1007/s40305-019-00287-4},
	doi = {10.1007/s40305-019-00287-4},
	language = {en},
	number = {2},
	urldate = {2020-06-24},
	journal = {Journal of the Operations Research Society of China},
	author = {Zhang, Hai-Miao and Dong, Bin},
	month = jun,
	year = {2020},
	pages = {311--340},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/Q25KULJ7/Zhang and Dong - 2020 - A Review on Deep Learning in Medical Image Reconst.pdf:application/pdf}
}

@incollection{mardani_neural_2018,
	title = {Neural {Proximal} {Gradient} {Descent} for {Compressive} {Imaging}},
	url = {http://papers.nips.cc/paper/8166-neural-proximal-gradient-descent-for-compressive-imaging.pdf},
	urldate = {2020-06-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 31},
	publisher = {Curran Associates, Inc.},
	author = {Mardani, Morteza and Sun, Qingyun and Donoho, David and Papyan, Vardan and Monajemi, Hatef and Vasanawala, Shreyas and Pauly, John},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
	pages = {9573--9583},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/J8EUUZXS/Mardani et al. - 2018 - Neural Proximal Gradient Descent for Compressive I.pdf:application/pdf}
}

@article{mardani_deep_2019,
	title = {Deep {Generative} {Adversarial} {Neural} {Networks} for {Compressive} {Sensing} {MRI}},
	volume = {38},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/8417964/},
	doi = {10.1109/TMI.2018.2858752},
	abstract = {Undersampled magnetic resonance image (MRI) reconstruction is typically an ill-posed linear inverse task. The time and resource intensive computations require trade offs between accuracy and speed. In addition, state-of-the-art compressed sensing (CS) analytics are not cognizant of the image diagnostic quality. To address these challenges, we propose a novel CS framework that uses generative adversarial networks (GAN) to model the (low-dimensional) manifold of high-quality MR images. Leveraging a mixture of least-squares (LS) GANs and pixel-wise 1/ 2 cost, a deep residual network with skip connections is trained as the generator that learns to remove the aliasing artifacts by projecting onto the image manifold. The LSGAN learns the texture details, while the 1/ 2 cost suppresses high-frequency noise. A discriminator network, which is a multilayer convolutional neural network (CNN), plays the role of a perceptual cost that is then jointly trained based on high quality MR images to score the quality of retrieved images. In the operational phase, an initial aliased estimate (e.g., simply obtained by zero-ﬁlling) is propagated into the trained generator to output the desired reconstruction. This demands very low computational overhead. Extensive evaluations are performed on a large contrast-enhanced MR dataset of pediatric patients. Images rated by expert radiologists corroborate that GANCS retrieves higher quality images with improved ﬁne texture details compared with conventional Wavelet-based and dictionary-learning based CS schemes as well as with deeplearning based schemes using pixel-wise training. In addition, it offers reconstruction times of under a few milliseconds, which is two orders of magnitude faster than current state-of-the-art CS-MRI schemes.},
	language = {en},
	number = {1},
	urldate = {2020-06-26},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Mardani, Morteza and Gong, Enhao and Cheng, Joseph Y. and Vasanawala, Shreyas S. and Zaharchuk, Greg and Xing, Lei and Pauly, John M.},
	month = jan,
	year = {2019},
	pages = {167--179},
	file = {Accepted Version:/home/gabrielziegler/Zotero/storage/26PF7TBN/Mardani et al. - 2019 - Deep Generative Adversarial Neural Networks for Co.pdf:application/pdf}
}

@article{makropoulos_review_2018,
	title = {A review on automatic fetal and neonatal brain {MRI} segmentation},
	volume = {170},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811917305451},
	doi = {10.1016/j.neuroimage.2017.06.074},
	abstract = {In recent years, a variety of segmentation methods have been proposed for automatic delineation of the fetal and neonatal brain MRI. These methods aim to deﬁne regions of interest of diﬀerent granularity: brain, tissue types or more localised structures. Diﬀerent methodologies have been applied for this segmentation task and can be classiﬁed into unsupervised, parametric, classiﬁcation, atlas fusion and deformable models. Brain atlases are commonly utilised as training data in the segmentation process. Challenges relating to the image acquisition, the rapid brain development as well as the limited availability of imaging data however hinder this segmentation task. In this paper, we review methods adopted for the perinatal brain and categorise them according to the target population, structures segmented and methodology. We outline diﬀerent methods proposed in the literature and discuss their major contributions. Diﬀerent approaches for the evaluation of the segmentation accuracy and benchmarks used for the segmentation quality are presented. We conclude this review with a discussion on shortcomings in the perinatal domain and possible future directions.},
	language = {en},
	urldate = {2020-06-26},
	journal = {NeuroImage},
	author = {Makropoulos, Antonios and Counsell, Serena J. and Rueckert, Daniel},
	month = apr,
	year = {2018},
	pages = {231--248},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/69M86YJE/Makropoulos et al. - 2018 - A review on automatic fetal and neonatal brain MRI.pdf:application/pdf}
}

@article{radford_unsupervised_2016,
	title = {Unsupervised {Representation} {Learning} with {Deep} {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1511.06434},
	abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
	urldate = {2020-07-03},
	journal = {arXiv:1511.06434 [cs]},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	month = jan,
	year = {2016},
	note = {arXiv: 1511.06434},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/9XRY5RLP/Radford et al. - 2016 - Unsupervised Representation Learning with Deep Con.pdf:application/pdf}
}

@incollection{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Nets}},
	url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
	urldate = {2020-07-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {2672--2680},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/EW979R6X/Goodfellow et al. - 2014 - Generative Adversarial Nets.pdf:application/pdf}
}

@article{liang_deep_2019,
	title = {Deep {MRI} {Reconstruction}: {Unrolled} {Optimization} {Algorithms} {Meet} {Neural} {Networks}},
	shorttitle = {Deep {MRI} {Reconstruction}},
	url = {http://arxiv.org/abs/1907.11711},
	abstract = {Image reconstruction from undersampled k-space data has been playing an important role for fast MRI. Recently, deep learning has demonstrated tremendous success in various fields and also shown potential to significantly speed up MR reconstruction with reduced measurements. This article gives an overview of deep learning-based image reconstruction methods for MRI. Three types of deep learning-based approaches are reviewed, the data-driven, model-driven and integrated approaches. The main structure of each network in three approaches is explained and the analysis of common parts of reviewed networks and differences in-between are highlighted. Based on the review, a number of signal processing issues are discussed for maximizing the potential of deep reconstruction for fast MRI. the discussion may facilitate further development of "optimal" network and performance analysis from a theoretical point of view.},
	urldate = {2020-06-24},
	journal = {arXiv:1907.11711 [physics, stat]},
	author = {Liang, Dong and Cheng, Jing and Ke, Ziwen and Ying, Leslie},
	month = jul,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing, Electrical Engineering and Systems Science - Signal Processing, Physics - Medical Physics}
}

@phdthesis{miosso_phd,
	type = {{PhD} {Thesis}},
	title = {Compressive {Sensing} with {Prior} {Information} {Applied} to {Magnetic} {Resonance} {Imaging}},
	school = {Department of Electrical and Computer Engineering, University of Texas at El Paso (UTEP)},
	author = {Miosso, Cristiano Jacques},
	file = {miosso_phd.pdf:/home/gabrielziegler/Zotero/storage/UVIK74EM/miosso_phd.pdf:application/pdf}
}

@article{miosso_compressive_2009,
	title = {Compressive {Sensing} {Reconstruction} {With} {Prior} {Information} by {Iteratively} {Reweighted} {Least}-{Squares}},
	volume = {57},
	issn = {1053-587X, 1941-0476},
	url = {http://ieeexplore.ieee.org/document/4799125/},
	doi = {10.1109/TSP.2009.2016889},
	abstract = {Iteratively reweighted least-squares (IRLS) algorithms have been successfully used in compressive sensing to reconstruct sparse signals from incomplete linear measurements taken in nonsparse domains. The underlying optimization problem corresponds to ﬁnding the vector that solves the minimization while explaining the measurements, and IRLS allows to easily control the used value of , with effect on the number of required measurements. In this paper, we propose a weighting strategy in the reconstruction method based on IRLS in order to add prior information on the support of the sparse domain. Our simulation results show that the use of prior knowledge about positions of at least some of the nonzero coefﬁcients in the sparse domain leads to a reduction in the number of linear measurements required for unambiguous reconstruction. This reduction occurs for all values of , so that a further reduction can be achieved by decreasing and using prior information. The proposed weighting scheme also reduces the computational complexity with respect to the IRLS with no prior information, both in terms of number of iterations and computation time.},
	language = {en},
	number = {6},
	urldate = {2020-03-30},
	journal = {IEEE Transactions on Signal Processing},
	author = {Miosso, C.J. and von Borries, R. and Argaez, M. and Velazquez, L. and Quintero, C. and Potes, C.M.},
	month = jun,
	year = {2009},
	pages = {2424--2431},
	file = {Miosso et al. - 2009 - Compressive Sensing Reconstruction With Prior Info.pdf:/home/gabrielziegler/Zotero/storage/HT2FZJKR/Miosso et al. - 2009 - Compressive Sensing Reconstruction With Prior Info.pdf:application/pdf}
}

@incollection{yang_deep_2016,
	title = {Deep {ADMM}-{Net} for {Compressive} {Sensing} {MRI}},
	url = {http://papers.nips.cc/paper/6406-deep-admm-net-for-compressive-sensing-mri.pdf},
	urldate = {2020-06-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {yang, yan and Sun, Jian and Li, Huibin and Xu, Zongben},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {10--18},
	file = {NIPS Full Text PDF:/home/gabrielziegler/Zotero/storage/HCRTT2SI/yang et al. - 2016 - Deep ADMM-Net for Compressive Sensing MRI.pdf:application/pdf;NIPS Snapshot:/home/gabrielziegler/Zotero/storage/ATV4HPWZ/6406-deep-admm-net-for-compressive-sensing-mri.html:text/html}
}

@article{donoho_compressed_2006,
	title = {Compressed sensing},
	volume = {52},
	issn = {0018-9448},
	url = {http://ieeexplore.ieee.org/document/1614066/},
	doi = {10.1109/TIT.2006.871582},
	abstract = {Suppose is an unknown vector in (a digital image or signal); we plan to measure general linear functionals of and then reconstruct. If is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure deﬁned here, the number of measurements can be dramatically smaller than the size . Thus, certain natural classes of images with pixels need only = ( 1 4 log5 2( )) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual pixel samples.},
	language = {en},
	number = {4},
	urldate = {2020-06-28},
	journal = {IEEE Transactions on Information Theory},
	author = {Donoho, D.L.},
	month = apr,
	year = {2006},
	pages = {1289--1306},
	file = {Donoho - 2006 - Compressed sensing.pdf:/home/gabrielziegler/Zotero/storage/T4Y59U8U/Donoho - 2006 - Compressed sensing.pdf:application/pdf}
}

@article{kabanikhin_definitions_2008,
	title = {Definitions and examples of inverse and ill-posed problems},
	volume = {16},
	issn = {0928-0219, 1569-3945},
	url = {https://www.degruyter.com/view/j/jiip.2008.16.issue-4/jiip.2008.019/jiip.2008.019.xml},
	doi = {10.1515/JIIP.2008.019},
	abstract = {The terms “inverse problems” and “ill-posed problems” have been steadily and surely gaining popularity in modern science since the middle of the 20th century. A little more than ﬁfty years of studying problems of this kind have shown that a great number of problems from various branches of classical mathematics (computational algebra, differential and integral equations, partial differential equations, functional analysis) can be classiﬁed as inverse or ill-posed, and they are among the most complicated ones (since they are unstable and usually nonlinear). At the same time, inverse and ill-posed problems began to be studied and applied systematically in physics, geophysics, medicine, astronomy, and all other areas of knowledge where mathematical methods are used. The reason is that solutions to inverse problems describe important properties of media under study, such as density and velocity of wave propagation, elasticity parameters, conductivity, dielectric permittivity and magnetic permeability, and properties and location of inhomogeneities in inaccessible areas, etc.},
	language = {en},
	number = {4},
	urldate = {2020-06-29},
	journal = {Journal of Inverse and Ill-posed Problems},
	author = {Kabanikhin, S. I.},
	month = jan,
	year = {2008},
	file = {Kabanikhin - 2008 - Definitions and examples of inverse and ill-posed .pdf:/home/gabrielziegler/Zotero/storage/9LZBXJZC/Kabanikhin - 2008 - Definitions and examples of inverse and ill-posed .pdf:application/pdf}
}

@book{bryan_introduction_2009,
	address = {Cambridge},
	title = {Introduction to the {Science} of {Medical} {Imaging}},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Bryan, R Nick},
	year = {2009},
	file = {Bryan - Introduction to the Science of Medical Imaging.pdf:/home/gabrielziegler/Zotero/storage/VHVQP73I/Bryan - Introduction to the Science of Medical Imaging.pdf:application/pdf}
}

@article{dias_metodos_nodate,
	title = {Métodos para {Reconstrução} de {Imagens} de {Tomografia} da {Coroa} {Solar} {Baseados} em},
	language = {pt},
	author = {Dias, Daniele},
	pages = {82},
	file = {Dias - Métodos para Reconstrução de Imagens de Tomografia.pdf:/home/gabrielziegler/Zotero/storage/HVWM76WR/Dias - Métodos para Reconstrução de Imagens de Tomografia.pdf:application/pdf}
}

@inproceedings{devlin_bert_2019,
	address = {Minneapolis, Minnesota},
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {https://www.aclweb.org/anthology/N19-1423},
	doi = {10.18653/v1/N19-1423},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2020-07-28},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = jun,
	year = {2019},
	pages = {4171--4186},
	file = {Full Text PDF:/home/gabrielziegler/Zotero/storage/C645MQ6Y/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf}
}

@article{wan_regularization_nodate,
	title = {Regularization of {Neural} {Networks} using {DropConnect}},
	abstract = {We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models.},
	language = {en},
	author = {Wan, Li and Zeiler, Matthew and Zhang, Sixin and {Yann LeCun}},
	pages = {12},
	file = {Wan et al. - Regularization of Neural Networks using DropConnec.pdf:/home/gabrielziegler/Zotero/storage/4BTAM5HN/Wan et al. - Regularization of Neural Networks using DropConnec.pdf:application/pdf}
}

@inproceedings{kim_enhancing_2019,
	address = {Copenhagen Denmark},
	title = {Enhancing {VAEs} for collaborative filtering: flexible priors \& gating mechanisms},
	isbn = {978-1-4503-6243-6},
	shorttitle = {Enhancing {VAEs} for collaborative filtering},
	url = {https://dl.acm.org/doi/10.1145/3298689.3347015},
	doi = {10.1145/3298689.3347015},
	language = {en},
	urldate = {2020-07-28},
	booktitle = {Proceedings of the 13th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Kim, Daeryong and Suh, Bongwon},
	month = sep,
	year = {2019},
	pages = {403--407},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/WML5YN8A/Kim and Suh - 2019 - Enhancing VAEs for collaborative filtering flexib.pdf:application/pdf}
}

@book{patterson_deep_2017,
	address = {Beijing},
	title = {Deep {Learning}: {A} {Practitioner}'s {Approach}},
	isbn = {978-1-4919-1425-0},
	url = {https://www.safaribooksonline.com/library/view/deep-learning/9781491924570/},
	abstract = {Although interest in machine learning has reached a high point, lofty expectations often scuttle projects before they get very far. How can machine learning—especially deep neural networks—make a real difference in your organization? This hands-on guide not only provides the most practical information available on the subject, but also helps you get started building efficient deep learning networks. The authors provide theory on deep learning before introducing their open-source Deeplearning4j (DL4J) library for developing production-class workflows. Through real-world examples, you will learn methods and strategies for training deep network architectures and running deep learning workflows on Spark and Hadoop with DL4J.},
	publisher = {O'Reilly},
	author = {Patterson, Josh and Gibson, Adam},
	year = {2017},
	keywords = {01841 102 safari book numerical ai software development learn java tool},
	file = {Josh Patterson, Adam Gibson - Deep Learning_ A Practitioner’s Approach (2017, O’Reilly Media) - libgen.lc.pdf:/home/gabrielziegler/Zotero/storage/QJ825QMM/Josh Patterson, Adam Gibson - Deep Learning_ A Practitioner’s Approach (2017, O’Reilly Media) - libgen.lc.pdf:application/pdf}
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	file = {Yoshua Bengio, Ian Goodfellow - Deep learning (2016, The MIT Press).pdf:/home/gabrielziegler/Zotero/storage/CFQURPIU/Yoshua Bengio, Ian Goodfellow - Deep learning (2016, The MIT Press).pdf:application/pdf}
}

@book{buduma_fundamentals_2017,
	edition = {1st},
	title = {Fundamentals of {Deep} {Learning}: {Designing} {Next}-{Generation} {Machine} {Intelligence} {Algorithms}},
	isbn = {1-4919-2561-2},
	publisher = {O’Reilly Media, Inc.},
	author = {Buduma, Nikhil and Locascio, Nicholas},
	year = {2017},
	file = {Buduma and Locascio - Fundamentals of Deep Learning.pdf:/home/gabrielziegler/Zotero/storage/JX43EYPU/Buduma and Locascio - Fundamentals of Deep Learning.pdf:application/pdf}
}

@article{rani_systematic_2018,
	title = {A {Systematic} {Review} of {Compressive} {Sensing}: {Concepts}, {Implementations} and {Applications}},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {A {Systematic} {Review} of {Compressive} {Sensing}},
	url = {http://ieeexplore.ieee.org/document/8260873/},
	doi = {10.1109/ACCESS.2018.2793851},
	abstract = {Compressive Sensing (CS) is a new sensing modality which compresses the signal being acquired at the time of sensing. Signals can have sparse or compressible representation either in original domain or in some transform domain. Relying on the sparsity of the signals, CS allows us to sample the signal at a rate much below the Nyquist sampling rate. Also, the varied reconstruction algorithms of CS can faithfully reconstruct the original signal back from fewer compressive measurements. This fact has stimulated research interest towards the use of CS in the several ﬁelds like magnetic resonance imaging, high speed video acquisition, ultrawideband (UWB) communication, etc. This survey paper reviews the basic theoretical concepts underlying CS. To bridge the gap between theory and practicality of CS, different CS acquisition strategies and reconstruction approaches are elaborated systematically in this paper. The major application areas where CS is currently being used are reviewed here. This paper also highlights some of the challenges and research directions in this ﬁeld.},
	language = {en},
	urldate = {2020-08-18},
	journal = {IEEE Access},
	author = {Rani, Meenu and Dhok, S. B. and Deshmukh, R. B.},
	year = {2018},
	pages = {4875--4894},
	file = {Rani et al. - 2018 - A Systematic Review of Compressive Sensing Concep.pdf:/home/gabrielziegler/Zotero/storage/7KS2MY84/Rani et al. - 2018 - A Systematic Review of Compressive Sensing Concep.pdf:application/pdf}
}

@article{ye_compressed_2019,
	title = {Compressed sensing {MRI}: a review from signal processing perspective},
	volume = {1},
	issn = {2524-4426},
	shorttitle = {Compressed sensing {MRI}},
	url = {https://bmcbiomedeng.biomedcentral.com/articles/10.1186/s42490-019-0006-z},
	doi = {10.1186/s42490-019-0006-z},
	abstract = {Magnetic resonance imaging (MRI) is an inherently slow imaging modality, since it acquires multi-dimensional kspace data through 1-D free induction decay or echo signals. This often limits the use of MRI, especially for high resolution or dynamic imaging. Accordingly, many investigators has developed various acceleration techniques to allow fast MR imaging. For the last two decades, one of the most important breakthroughs in this direction is the introduction of compressed sensing (CS) that allows accurate reconstruction from sparsely sampled k-space data. The recent FDA approval of compressed sensing products for clinical scans clearly reflect the maturity of this technology. Therefore, this paper reviews the basic idea of CS and how this technology have been evolved for various MR imaging problems.},
	language = {en},
	number = {1},
	urldate = {2020-08-18},
	journal = {BMC Biomedical Engineering},
	author = {Ye, Jong Chul},
	month = dec,
	year = {2019},
	pages = {8},
	file = {Ye - 2019 - Compressed sensing MRI a review from signal proce.pdf:/home/gabrielziegler/Zotero/storage/2S4TIBQB/Ye - 2019 - Compressed sensing MRI a review from signal proce.pdf:application/pdf}
}

@article{candes_introduction_2008,
	title = {An {Introduction} {To} {Compressive} {Sampling}},
	volume = {25},
	issn = {1053-5888},
	url = {http://ieeexplore.ieee.org/document/4472240/},
	doi = {10.1109/MSP.2007.914731},
	language = {en},
	number = {2},
	urldate = {2020-08-18},
	journal = {IEEE Signal Processing Magazine},
	author = {Candes, E.J. and Wakin, M.B.},
	month = mar,
	year = {2008},
	pages = {21--30},
	file = {Candes and Wakin - 2008 - An Introduction To Compressive Sampling.pdf:/home/gabrielziegler/Zotero/storage/J5IJ2P6S/Candes and Wakin - 2008 - An Introduction To Compressive Sampling.pdf:application/pdf}
}

@inproceedings{miosso_prefiltering_2009,
	address = {Pacific Grove, CA, USA},
	title = {Compressive sensing method for improved reconstruction of gradient-sparse magnetic resonance images},
	isbn = {978-1-4244-5825-7},
	url = {http://ieeexplore.ieee.org/document/5469970/},
	doi = {10.1109/ACSSC.2009.5469970},
	abstract = {We propose a compressive sensing method for reconstructing gradient-sparse magnetic resonance (MR) images based on the pre-ﬁltering of the input signals in the k-space. A set of ﬁltered versions of the image is reconstructed using the available k-space samples, and a ﬁnal reconstruction stage generates the desired image from the ﬁltered versions. Our experiments, conducted over real MR images and angiograms, show that the proposed method improves the reconstruction over the total-variation minimization, in terms of signal-to-noise ratio and computation time. The proposed method is particularly appropriate for computing MR angiograms, which are typically sparse under the ﬁnite-differences operation.},
	language = {en},
	urldate = {2020-08-28},
	booktitle = {2009 {Conference} {Record} of the {Forty}-{Third} {Asilomar} {Conference} on {Signals}, {Systems} and {Computers}},
	publisher = {IEEE},
	author = {Miosso, C. J. and von Borries, R. and Pierluissi, J. H.},
	year = {2009},
	pages = {799--806},
	file = {Miosso et al. - 2009 - Compressive sensing method for improved reconstruc.pdf:/home/gabrielziegler/Zotero/storage/UV2MDUG6/Miosso et al. - 2009 - Compressive sensing method for improved reconstruc.pdf:application/pdf}
}

@inproceedings{chen_brain_2018,
	address = {Washington, DC},
	title = {Brain {MRI} super resolution using {3D} deep densely connected neural networks},
	isbn = {978-1-5386-3636-7},
	url = {https://ieeexplore.ieee.org/document/8363679/},
	doi = {10.1109/ISBI.2018.8363679},
	abstract = {Magnetic resonance image (MRI) in high spatial resolution provides detailed anatomical information and is often necessary for accurate quantitative analysis. However, high spatial resolution typically comes at the expense of longer scan time, less spatial coverage, and lower signal to noise ratio (SNR). Single Image Super-Resolution (SISR), a technique aimed to restore high-resolution (HR) details from one single low-resolution (LR) input image, has been improved dramatically by recent breakthroughs in deep learning. In this paper, we introduce a new neural network architecture, 3D Densely Connected Super-Resolution Networks (DCSRN) to restore HR features of structural brain MR images. Through experiments on a dataset with 1,113 subjects, we demonstrate that our network outperforms bicubic interpolation as well as other deep learning methods in restoring 4x resolution-reduced images.},
	language = {en},
	urldate = {2020-09-29},
	booktitle = {2018 {IEEE} 15th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2018)},
	publisher = {IEEE},
	author = {Chen, Yuhua and Xie, Yibin and Zhou, Zhengwei and Shi, Feng and Christodoulou, Anthony G. and Li, Debiao},
	month = apr,
	year = {2018},
	pages = {739--742},
	file = {Chen et al. - 2018 - Brain MRI super resolution using 3D deep densely c.pdf:/home/gabrielziegler/Zotero/storage/6IIIWACX/Chen et al. - 2018 - Brain MRI super resolution using 3D deep densely c.pdf:application/pdf}
}

@article{yang_dagan_2018,
	title = {{DAGAN}: {Deep} {De}-{Aliasing} {Generative} {Adversarial} {Networks} for {Fast} {Compressed} {Sensing} {MRI} {Reconstruction}},
	volume = {37},
	issn = {0278-0062, 1558-254X},
	shorttitle = {{DAGAN}},
	url = {https://ieeexplore.ieee.org/document/8233175/},
	doi = {10.1109/TMI.2017.2785879},
	abstract = {Compressed Sensing Magnetic Resonance Imaging (CS-MRI) enables fast acquisition, which is highly desirable for numerous clinical applications. This can not only reduce the scanning cost and ease patient burden, but also potentially reduce motion artefacts and the effect of contrast washout, thus yielding better image quality. Different from parallel imaging based fast MRI, which utilises multiple coils to simultaneously receive MR signals, CS-MRI breaks the Nyquist-Shannon sampling barrier to reconstruct MRI images with much less required raw data. This paper provides a deep learning based strategy for reconstruction of CS-MRI, and bridges a substantial gap between conventional non-learning methods working only on data from a single image, and prior knowledge from large training datasets. In particular, a novel conditional Generative Adversarial Networks-based model (DAGAN) is proposed to reconstruct CS-MRI. In our DAGAN architecture, we have designed a reﬁnement learning method to stabilise our U-Net based generator, which provides an endto-end network to reduce aliasing artefacts. To better preserve texture and edges in the reconstruction, we have coupled the adversarial loss with an innovative content loss. In addition, we incorporate frequency domain information to enforce similarity in both the image and frequency domains. We have performed comprehensive comparison studies with both conventional CSMRI reconstruction methods and newly investigated deep learning approaches. Compared to these methods, our DAGAN method provides superior reconstruction with preserved perceptual image details. Furthermore, each image is reconstructed in about 5 ms, which is suitable for real-time processing.},
	language = {en},
	number = {6},
	urldate = {2020-10-06},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Yang, Guang and Yu, Simiao and Dong, Hao and Slabaugh, Greg and Dragotti, Pier Luigi and Ye, Xujiong and Liu, Fangde and Arridge, Simon and Keegan, Jennifer and Guo, Yike and Firmin, David},
	month = jun,
	year = {2018},
	pages = {1310--1321},
	file = {Yang et al. - 2018 - DAGAN Deep De-Aliasing Generative Adversarial Net.pdf:/home/gabrielziegler/Zotero/storage/ZZE822BR/Yang et al. - 2018 - DAGAN Deep De-Aliasing Generative Adversarial Net.pdf:application/pdf}
}

@article{gupta_super-resolution_2020,
	title = {Super-{Resolution} using {GANs} for {Medical} {Imaging}},
	volume = {173},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050920315076},
	doi = {10.1016/j.procs.2020.06.005},
	language = {en},
	urldate = {2020-10-07},
	journal = {Procedia Computer Science},
	author = {Gupta, Rohit and Sharma, Anurag and Kumar, Anupam},
	year = {2020},
	pages = {28--35},
	file = {Gupta et al. - 2020 - Super-Resolution using GANs for Medical Imaging.pdf:/home/gabrielziegler/Zotero/storage/ZX9VN576/Gupta et al. - 2020 - Super-Resolution using GANs for Medical Imaging.pdf:application/pdf}
}

@article{cole_unsupervised_2020,
	title = {Unsupervised {MRI} {Reconstruction} with {Generative} {Adversarial} {Networks}},
	abstract = {Deep learning-based image reconstruction methods have achieved promising results across multiple MRI applications. However, most approaches require largescale fully-sampled ground truth data for supervised training. Acquiring fully-sampled data is often either difficult or impossible, particularly for dynamic contrast enhancement (DCE), 3D cardiac cine, and 4D flow. We present a deep learning framework for MRI reconstruction without any fully-sampled data using generative adversarial networks. We test the proposed method in two scenarios: retrospectively undersampled fast spin echo knee exams and prospectively undersampled abdominal DCE. The method recovers more anatomical structure compared to conventional methods.},
	language = {en},
	author = {Cole, Elizabeth K and Pauly, John M and Vasanawala, Shreyas S and Ong, Frank},
	pages = {8},
	year = {2020},
	file = {Cole et al. - Unsupervised MRI Reconstruction with Generative Ad.pdf:/home/gabrielziegler/Zotero/storage/BYPKAB42/Cole et al. - Unsupervised MRI Reconstruction with Generative Ad.pdf:application/pdf}
}

@article{knoll_advancing_2020,
	title = {Advancing machine learning for {MR} image reconstruction with an open competition: {Overview} of the 2019 {fastMRI} challenge},
	volume = {84},
	issn = {0740-3194, 1522-2594},
	shorttitle = {Advancing machine learning for {MR} image reconstruction with an open competition},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/mrm.28338},
	doi = {10.1002/mrm.28338},
	abstract = {Purpose: To advance research in the field of machine learning for MR image reconstruction with an open challenge.
Methods: We provided participants with a dataset of raw k-space data from 1,594 consecutive clinical exams of the knee. The goal of the challenge was to reconstruct images from these data. In order to strike a balance between realistic data and a shallow learning curve for those not already familiar with MR image reconstruction, we ran multiple tracks for multi-coil and single-coil data. We performed a two-stage evaluation based on quantitative image metrics followed by evaluation by a panel of radiologists. The challenge ran from June to December of 2019.
Results: We received a total of 33 challenge submissions. All participants chose to submit results from supervised machine learning approaches.
Conclusions: The challenge led to new developments in machine learning for image reconstruction, provided insight into the current state of the art in the field, and highlighted remaining hurdles for clinical adoption.},
	language = {en},
	number = {6},
	urldate = {2020-10-11},
	journal = {Magnetic Resonance in Medicine},
	author = {Knoll, Florian and Murrell, Tullie and Sriram, Anuroop and Yakubova, Nafissa and Zbontar, Jure and Rabbat, Michael and Defazio, Aaron and Muckley, Matthew J. and Sodickson, Daniel K. and Zitnick, C. Lawrence and Recht, Michael P.},
	month = dec,
	year = {2020},
	pages = {3054--3070},
	file = {Knoll et al. - 2020 - Advancing machine learning for MR image reconstruc.pdf:/home/gabrielziegler/Zotero/storage/7VLIN5G4/Knoll et al. - 2020 - Advancing machine learning for MR image reconstruc.pdf:application/pdf}
}

@article{zbontar_fastmri_2019,
	title = {{fastMRI}: {An} {Open} {Dataset} and {Benchmarks} for {Accelerated} {MRI}},
	shorttitle = {{fastMRI}},
	url = {http://arxiv.org/abs/1811.08839},
	abstract = {Accelerating Magnetic Resonance Imaging (MRI) by taking fewer measurements has the potential to reduce medical costs, minimize stress to patients and make MRI possible in applications where it is currently prohibitively slow or expensive. We introduce the fastMRI dataset, a large-scale collection of both raw MR measurements and clinical MR images, that can be used for training and evaluation of machine-learning approaches to MR image reconstruction. By introducing standardized evaluation criteria and a freely-accessible dataset, our goal is to help the community make rapid advances in the state of the art for MR image reconstruction. We also provide a self-contained introduction to MRI for machine learning researchers with no medical imaging background.},
	urldate = {2020-10-11},
	journal = {arXiv:1811.08839 [physics, stat]},
	author = {Zbontar, Jure and Knoll, Florian and Sriram, Anuroop and Murrell, Tullie and Huang, Zhengnan and Muckley, Matthew J. and Defazio, Aaron and Stern, Ruben and Johnson, Patricia and Bruno, Mary and Parente, Marc and Geras, Krzysztof J. and Katsnelson, Joe and Chandarana, Hersh and Zhang, Zizhao and Drozdzal, Michal and Romero, Adriana and Rabbat, Michael and Vincent, Pascal and Yakubova, Nafissa and Pinkerton, James and Wang, Duo and Owens, Erich and Zitnick, C. Lawrence and Recht, Michael P. and Sodickson, Daniel K. and Lui, Yvonne W.},
	month = dec,
	year = {2019},
	note = {arXiv: 1811.08839},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Signal Processing, Physics - Medical Physics},
	file = {arXiv Fulltext PDF:/home/gabrielziegler/Zotero/storage/54LQZ9W2/Zbontar et al. - 2019 - fastMRI An Open Dataset and Benchmarks for Accele.pdf:application/pdf;arXiv.org Snapshot:/home/gabrielziegler/Zotero/storage/5CYIN98L/1811.html:text/html}
}

@article{hyun_deep_2018,
	title = {Deep learning for undersampled {MRI} reconstruction},
	volume = {63},
	issn = {1361-6560},
	url = {https://iopscience.iop.org/article/10.1088/1361-6560/aac71a},
	doi = {10.1088/1361-6560/aac71a},
	abstract = {This paper presents a deep learning method for faster magnetic resonance imaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and provides a rationale for why the proposed approach works well. Uniform subsampling is used in the time-consuming phaseencoding direction to capture high-resolution image information, while permitting the imagefolding problem dictated by the Poisson summation formula. To deal with the localization uncertainty due to image folding, a small number of low-frequency k-space data are added. Training the deep learning net involves input and output images that are pairs of the Fourier transforms of the subsampled and fully sampled k-space data. Our experiments show the remarkable performance of the proposed method; only 29\% of the k-space data can generate images of high quality as effectively as standard MRI reconstruction with the fully sampled data.},
	language = {en},
	number = {13},
	urldate = {2020-11-02},
	journal = {Physics in Medicine \& Biology},
	author = {Hyun, Chang Min and Kim, Hwa Pyung and Lee, Sung Min and Lee, Sungchul and Seo, Jin Keun},
	month = jun,
	year = {2018},
	pages = {135007},
	file = {Hyun et al. - 2018 - Deep learning for undersampled MRI reconstruction.pdf:/home/gabrielziegler/Zotero/storage/6QD3DX7E/Hyun et al. - 2018 - Deep learning for undersampled MRI reconstruction.pdf:application/pdf}
}

@article{lauterbur_image_1973,
	title = {Image {Formation} by {Induced} {Local} {Interactions}: {Examples} {Employing} {Nuclear} {Magnetic} {Resonance}},
	volume = {242},
	issn = {0028-0836, 1476-4687},
	shorttitle = {Image {Formation} by {Induced} {Local} {Interactions}},
	url = {http://www.nature.com/articles/242190a0},
	doi = {10.1038/242190a0},
	language = {en},
	number = {5394},
	urldate = {2020-11-02},
	journal = {Nature},
	author = {Lauterbur, P. C.},
	month = mar,
	year = {1973},
	pages = {190--191},
	file = {Lauterbur - 1973 - Image Formation by Induced Local Interactions Exa.pdf:/home/gabrielziegler/Zotero/storage/5G7XDV7W/Lauterbur - 1973 - Image Formation by Induced Local Interactions Exa.pdf:application/pdf}
}


@incollection{salimans_improved_2016,
	title = {Improved {Techniques} for {Training} {GANs}},
	url = {http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf},
	urldate = {2020-11-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	pages = {2234--2242},
	file = {NIPS Full Text PDF:/home/gabrielziegler/Zotero/storage/U9VAW9WU/Salimans et al. - 2016 - Improved Techniques for Training GANs.pdf:application/pdf;NIPS Snapshot:/home/gabrielziegler/Zotero/storage/QEN6DDM8/6125-improved-techniques-for-training-gans.html:text/html}
}

@article{sandino_deep_nodate,
	title = {Deep convolutional neural networks for accelerated dynamic magnetic resonance imaging},
	abstract = {Dynamic magnetic resonance imaging (MRI) scans can be accelerated by utilizing compressed sensing (CS) reconstruction methods that allow for diagnostic quality images to be generated from undersampled data. Unfortunately, CS reconstruction is time-consuming, requiring hours between a dynamic MRI scan and image availability for diagnosis. In this work, we train a convolutional neural network (CNN) to perform fast reconstruction of severely undersampled dynamic cardiac MRI data, and we explore the utility of CNNs for further accelerating dynamic MRI scan times. Compared to state-of-the-art CS reconstruction techniques, our CNN achieves reconstruction speeds that are 150x faster without signiﬁcant loss of image quality. Additionally, preliminary results suggest that CNNs may allow scan times that are 2x faster than those allowed by CS.},
	language = {en},
	author = {Sandino, Christopher M and Dixit, Neerav and Cheng, Joseph Y and Vasanawala, Shreyas S},
	pages = {8},
	file = {Sandino et al. - Deep convolutional neural networks for accelerated.pdf:/home/gabrielziegler/Zotero/storage/XVPCJMFU/Sandino et al. - Deep convolutional neural networks for accelerated.pdf:application/pdf}
}

@inproceedings{wang_high-resolution_2018,
	address = {Salt Lake City, UT, USA},
	title = {High-{Resolution} {Image} {Synthesis} and {Semantic} {Manipulation} with {Conditional} {GANs}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8579015/},
	doi = {10.1109/CVPR.2018.00917},
	urldate = {2020-11-03},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
	month = jun,
	year = {2018},
	pages = {8798--8807},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/FTCVYZN3/Wang et al. - 2018 - High-Resolution Image Synthesis and Semantic Manip.pdf:application/pdf}
}

@article{mota_compressed_2017,
	title = {Compressed {Sensing} {With} {Prior} {Information}: {Strategies}, {Geometry}, and {Bounds}},
	volume = {63},
	issn = {0018-9448, 1557-9654},
	shorttitle = {Compressed {Sensing} {With} {Prior} {Information}},
	url = {https://ieeexplore.ieee.org/document/7904593/},
	doi = {10.1109/TIT.2017.2695614},
	number = {7},
	urldate = {2020-11-04},
	journal = {IEEE Transactions on Information Theory},
	author = {Mota, Joao F. C. and Deligiannis, Nikos and Rodrigues, Miguel R. D.},
	month = jul,
	year = {2017},
	pages = {4472--4496},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/PVLWE8BE/Mota et al. - 2017 - Compressed Sensing With Prior Information Strateg.pdf:application/pdf}
}

@inproceedings{zhang_compressed_2017,
	address = {Aachen, Germany},
	title = {Compressed sensing with prior information via maximizing correlation},
	isbn = {978-1-5090-4096-4},
	url = {http://ieeexplore.ieee.org/document/8006522/},
	doi = {10.1109/ISIT.2017.8006522},
	urldate = {2020-11-04},
	booktitle = {2017 {IEEE} {International} {Symposium} on {Information} {Theory} ({ISIT})},
	publisher = {IEEE},
	author = {Zhang, Xu and Cui, Wei and Liu, Yulong},
	month = jun,
	year = {2017},
	pages = {221--225},
	file = {Submitted Version:/home/gabrielziegler/Zotero/storage/TLHPVZF3/Zhang et al. - 2017 - Compressed sensing with prior information via maxi.pdf:application/pdf}
}

@article{kutyniok_compressed_nodate,
	title = {Compressed {Sensing}},
	language = {en},
	author = {Kutyniok, Gitta and Eldar, Yonina C},
	pages = {558},
	file = {Kutyniok and Eldar - Compressed Sensing.pdf:/home/gabrielziegler/Zotero/storage/QC6ERCHV/Kutyniok and Eldar - Compressed Sensing.pdf:application/pdf}
}

@book{carmi_compressed_2014,
	address = {Berlin, Heidelberg},
	series = {Signals and {Communication} {Technology}},
	title = {Compressed {Sensing} \& {Sparse} {Filtering}},
	isbn = {978-3-642-38397-7 978-3-642-38398-4},
	url = {http://link.springer.com/10.1007/978-3-642-38398-4},
	language = {en},
	urldate = {2020-11-05},
	publisher = {Springer Berlin Heidelberg},
	editor = {Carmi, Avishy Y. and Mihaylova, Lyudmila and Godsill, Simon J.},
	year = {2014},
	doi = {10.1007/978-3-642-38398-4},
	file = {Carmi et al. - 2014 - Compressed Sensing & Sparse Filtering.pdf:/home/gabrielziegler/Zotero/storage/2KI63Z4X/Carmi et al. - 2014 - Compressed Sensing & Sparse Filtering.pdf:application/pdf}
}

@article{shepp_fourier_1974,
	title = {The {Fourier} reconstruction of a head section},
	volume = {21},
	doi = {10.1109/TNS.1974.6499235},
	number = {3},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Shepp, L. A. and Logan, B. F.},
	year = {1974},
	pages = {21--43}
}

@misc{oreilly_gan,
	title = {Deep convolutional generative adversarial networks with TensorFlow},
	author = {Dominic Monn},
    note = {Available at: \url{https://www.oreilly.com/content/deep-convolutional-generative-adversarial-networks-with-tensorflow/}. Last access on November 18th, 2020},
	year = {2017}
}

@article{radford_unsupervised_2016,
	title = {Unsupervised {Representation} {Learning} with {Deep} {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1511.06434},
	abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
	urldate = {2020-07-03},
	journal = {arXiv:1511.06434 [cs]},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	month = jan,
	year = {2016},
	note = {arXiv: 1511.06434},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/9XRY5RLP/Radford et al. - 2016 - Unsupervised Representation Learning with Deep Con.pdf:application/pdf}
}

@article{empirical_relu_cnn,
  author    = {Bing Xu and
               Naiyan Wang and
               Tianqi Chen and
               Mu Li},
  title     = {Empirical Evaluation of Rectified Activations in Convolutional Network},
  journal   = {CoRR},
  volume    = {abs/1505.00853},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.00853},
  archivePrefix = {arXiv},
  eprint    = {1505.00853},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/XuWCL15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{maas_rectier_nodate,
	title = {Rectifier {Nonlinearities} {Improve} {Neural} {Network} {Acoustic} {Models}},
	abstract = {Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectiﬁed linear (ReL) hidden units demonstrates additional gains in ﬁnal system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectiﬁer networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectiﬁer nonlinearities produce 2\% absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify diﬀerences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectiﬁer networks.},
	language = {en},
	author = {Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y},
	pages = {6},
	file = {Maas et al. - Rectiﬁer Nonlinearities Improve Neural Network Aco.pdf:/home/gabrielziegler/Zotero/storage/ISDSD5VE/Maas et al. - Rectiﬁer Nonlinearities Improve Neural Network Aco.pdf:application/pdf}
}

@article{hahnloser_digital_2000,
	title = {Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit},
	volume = {405},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/35016072},
	doi = {10.1038/35016072},
	language = {en},
	number = {6789},
	urldate = {2020-11-20},
	journal = {Nature},
	author = {Hahnloser, Richard H. R. and Sarpeshkar, Rahul and Mahowald, Misha A. and Douglas, Rodney J. and Seung, H. Sebastian},
	month = jun,
	year = {2000},
	pages = {947--951}
}

@INPROCEEDINGS{trottier_2017,  author={L. {Trottier} and P. {Giguere} and B. {Chaib-draa}},  booktitle={2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)},   title={Parametric Exponential Linear Unit for Deep Convolutional Neural Networks},   year={2017},  volume={},  number={},  pages={207-214},  doi={10.1109/ICMLA.2017.00038}}

@article{deep_learning_relu,
  author    = {Abien Fred Agarap},
  title     = {Deep Learning using Rectified Linear Units (ReLU)},
  journal   = {CoRR},
  volume    = {abs/1803.08375},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.08375},
  archivePrefix = {arXiv},
  eprint    = {1803.08375},
  timestamp = {Mon, 13 Aug 2018 16:47:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-08375.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{quddus_machine_2018,
	title = {Machine {Learning} with {Apache} {Spark} {Quick} {Start} {Guide}: {Uncover} patterns, derive actionable insights, and learn from big data using {MLlib}},
	isbn = {978-1-78934-937-5},
	url = {https://books.google.com.br/books?id=0Z2BDwAAQBAJ},
	publisher = {Packt Publishing},
	author = {Quddus, J.},
	year = {2018}
}

@article{backpropagation_1986,
  added-at = {2019-05-21T10:10:49.000+0200},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  biburl = {https://www.bibsonomy.org/bibtex/2a392597c4f9cff2cd3c96c2191fa1eb6/sxkdz},
  doi = {10.1038/323533a0},
  interhash = {c354bc293fa9aa7caffc66d40a014903},
  intrahash = {a392597c4f9cff2cd3c96c2191fa1eb6},
  journal = {Nature},
  keywords = {imported},
  number = 6088,
  pages = {533--536},
  timestamp = {2019-05-21T10:10:49.000+0200},
  title = {{Learning Representations by Back-propagating Errors}},
  url = {http://www.nature.com/articles/323533a0},
  volume = 323,
  year = 1986
}

@book{langr_gans_2019,
	address = {Shelter Island, New York},
	title = {{GANs} in action: deep learning with generative adversarial networks},
	isbn = {978-1-61729-556-0},
	shorttitle = {{GANs} in action},
	abstract = {Generative Adversarial Networks, GANs, are an incredible AI technology capable of creating images, sound, and videos that are indistinguishable from the "real thing". By pitting two neural networks against each other, one to generate fakes and one to spot them, GANs rapidly learn to produce photo-realistic faces and other media objects. With the potential to produce stunningly realistic animations or shocking deepfakes, GANs are a huge step forward in deep learning systems. "GANs in action" teaches you to build and train your own Generative Adversarial Networks. You'll start by creating simple generator and discriminator networks that are the foundation of GAN architecture. Then, following numerous hands-on examples, you'll train GANs to generate high-resolution images, image-to-image translation, and targeted data generation. Along the way, you'll find pro tips for making your system smart, effective, and fast},
	language = {en},
	publisher = {Manning Publications},
	author = {Langr, Jakub and Bok, Vladimir},
	year = {2019},
	note = {OCLC: on1050335878},
	keywords = {Machine learning, Artificial intelligence, Computer programs, Technological innovations},
}

@ARTICLE{deep_magnetic_2020,
  author={D. {Liang} and J. {Cheng} and Z. {Ke} and L. {Ying}},
  journal={IEEE Signal Processing Magazine},
  title={Deep Magnetic Resonance Image Reconstruction: Inverse Problems Meet Neural Networks},
  year={2020},
  volume={37},
  number={1},
  pages={141-151},
  doi={10.1109/MSP.2019.2950557}
}

@misc{gradient_descent_2020,
	title = {Gradient descent relies on trial and error to optimize an algorithm, aiming for minima in a 3D landscape. Adapted by M. Atarod/Science},
	author = {Alexander Amini, Daniela Rus.},
    note = {Available at: \url{https://www.sciencemag.org/news/2018/05/ai-researchers-allege-machine-learning-alchemy}. Last access on November 30th, 2020},
	year = {2020}
}

@book{werbos_1994,
    author = {Werbos, Paul John},
    title = {The Roots of Backpropagation: From Ordered Derivatives to Neural Networks and Political Forecasting},
    year = {1994},
    isbn = {0471598976},
    publisher = {Wiley-Interscience},
    address = {USA}
}

@book{haykin_neural_2009,
	address = {New York},
	edition = {3rd ed},
	title = {Neural networks and learning machines},
	isbn = {978-0-13-147139-9},
	language = {en},
	publisher = {Prentice Hall},
	author = {Haykin, Simon S. and Haykin, Simon S.},
	year = {2009},
	note = {OCLC: ocn237325326},
	keywords = {Adaptive filters, Neural networks (Computer science)},
	file = {Haykin and Haykin - 2009 - Neural networks and learning machines.pdf:/home/gabrielziegler/Zotero/storage/TQFSCVMZ/Haykin and Haykin - 2009 - Neural networks and learning machines.pdf:application/pdf}
}

@article{donoho_for_2004,
	title = {For {Most} {Large} {Underdetermined} {Systems} of {Linear} {Equations} the {Minimal} ℓ1-norm {Solution} is also the {Sparsest} {Solution}},
	volume = {59},
	abstract = {We consider linear equations y = Φα where y is a given vector in R n, Φ is a given n by m matrix with n {\textless} m ≤ An, and we wish to solve for α ∈ R m. We suppose that the columns of Φ are normalized to unit ℓ 2 norm 1 and we place uniform measure on such Φ. We prove the existence of ρ = ρ(A) so that for large n, and for all Φ’s except a negligible fraction, the following property holds: For every y having a representation y = Φα0 by a coefficient vector α0 ∈ R m with fewer than ρ · n nonzeros, the solution α1 of the ℓ 1 minimization problem min �x�1 subject to Φα = y is unique and equal to α0. In contrast, heuristic attempts to sparsely solve such systems – greedy algorithms and thresholding – perform poorly in this challenging setting. The techniques include the use of random proportional embeddings and almost-spherical sections in Banach space theory, and deviation bounds for the eigenvalues of random Wishart matrices.},
	journal = {Comm. Pure Appl. Math},
	author = {Donoho, David L.},
	year = {2004},
	pages = {797--829},
	file = {Citeseer - Full Text PDF:/home/gabrielziegler/Zotero/storage/D79UYUAF/Donoho - 2004 - For Most Large Underdetermined Systems of Linear E.pdf:application/pdf;Citeseer - Snapshot:/home/gabrielziegler/Zotero/storage/XYHEWMA6/download.html:text/html}
}

@article{quan_compressed_2018,
	title = {Compressed {Sensing} {MRI} {Reconstruction} {Using} a {Generative} {Adversarial} {Network} {With} a {Cyclic} {Loss}},
	volume = {37},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/8327637/},
	doi = {10.1109/TMI.2018.2820120},
	abstract = {Compressed Sensing MRI (CS-MRI) has provided theoretical foundations upon which the time-consuming MRI acquisition process can be accelerated. However, it primarily relies on iterative numerical solvers which still hinders their adaptation in time-critical applications. In addition, recent advances in deep neural networks have shown their potential in computer vision and image processing, but their adaptation to MRI reconstruction is still in an early stage. In this paper, we propose a novel deep learning-based generative adversarial model, ReﬁneGAN, for fast and accurate CS-MRI reconstruction. The proposed model is a variant of fully-residual convolutional autoencoder and generative adversarial networks (GANs), speciﬁcally designed for CS-MRI formulation; it employs deeper generator and discriminator networks with cyclic data consistency loss for faithful interpolation in the given under-sampled k-space data. In addition, our solution leverages a chained network to further enhance the reconstruction quality. ReﬁneGAN is fast and accurate – the reconstruction process is extremely rapid, as low as tens of milliseconds for reconstruction of a 256x256 image, because it is one-way deployment on a feed-forward network, and the image quality is superior even for extremely low sampling rate (as low as 10\%) due to the data-driven nature of the method. We demonstrate that ReﬁneGAN outperforms the state-of-the-art CS-MRI methods by a large margin in terms of both running time and image quality via evaluation using several open-source MRI databases.},
	language = {en},
	number = {6},
	urldate = {2021-02-27},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Quan, Tran Minh and Nguyen-Duc, Thanh and Jeong, Won-Ki},
	month = jun,
	year = {2018},
	pages = {1488--1497},
	file = {Quan et al. - 2018 - Compressed Sensing MRI Reconstruction Using a Gene.pdf:/home/gabrielziegler/Zotero/storage/MZ8GV2TM/Quan et al. - 2018 - Compressed Sensing MRI Reconstruction Using a Gene.pdf:application/pdf}
}

@article{knoll_fastmri_2020,
	title = {{fastMRI}: {A} {Publicly} {Available} {Raw} k-{Space} and {DICOM} {Dataset} of {Knee} {Images} for {Accelerated} {MR} {Image} {Reconstruction} {Using} {Machine} {Learning}},
	volume = {2},
	issn = {2638-6100},
	shorttitle = {{fastMRI}},
	url = {http://pubs.rsna.org/doi/10.1148/ryai.2020190007},
	doi = {10.1148/ryai.2020190007},
	language = {en},
	number = {1},
	urldate = {2021-02-28},
	journal = {Radiology: Artificial Intelligence},
	author = {Knoll, Florian and Zbontar, Jure and Sriram, Anuroop and Muckley, Matthew J. and Bruno, Mary and Defazio, Aaron and Parente, Marc and Geras, Krzysztof J. and Katsnelson, Joe and Chandarana, Hersh and Zhang, Zizhao and Drozdzalv, Michal and Romero, Adriana and Rabbat, Michael and Vincent, Pascal and Pinkerton, James and Wang, Duo and Yakubova, Nafissa and Owens, Erich and Zitnick, C. Lawrence and Recht, Michael P. and Sodickson, Daniel K. and Lui, Yvonne W.},
	month = jan,
	year = {2020},
	pages = {e190007},
	file = {Knoll et al. - 2020 - fastMRI A Publicly Available Raw k-Space and DICO.pdf:/home/gabrielziegler/Zotero/storage/9WIE6QMP/Knoll et al. - 2020 - fastMRI A Publicly Available Raw k-Space and DICO.pdf:application/pdf}
}

@article{cole_unsupervised_2020,
	title = {Unsupervised {MRI} {Reconstruction} with {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/2008.13065},
	abstract = {Deep learning-based image reconstruction methods have achieved promising results across multiple MRI applications. However, most approaches require large-scale fully-sampled ground truth data for supervised training. Acquiring fully-sampled data is often either difficult or impossible, particularly for dynamic contrast enhancement (DCE), 3D cardiac cine, and 4D flow. We present a deep learning framework for MRI reconstruction without any fully-sampled data using generative adversarial networks. We test the proposed method in two scenarios: retrospectively undersampled fast spin echo knee exams and prospectively undersampled abdominal DCE. The method recovers more anatomical structure compared to conventional methods.},
	urldate = {2020-10-11},
	journal = {arXiv:2008.13065 [cs, eess, stat]},
	author = {Cole, Elizabeth K. and Pauly, John M. and Vasanawala, Shreyas S. and Ong, Frank},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.13065
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv.org Snapshot:/home/gabrielziegler/Zotero/storage/57J4VRPK/Cole et al. - 2020 - Unsupervised MRI Reconstruction with Generative Ad.html:text/html}
}

@article{lyu_super-resolution_2018,
	title = {Super-resolution {MRI} through {Deep} {Learning}},
	url = {http://arxiv.org/abs/1810.06776},
	abstract = {Magnetic resonance imaging (MRI) is extensively used for diagnosis and image-guided therapeutics. Due to hardware, physical and physiological limitations, acquisition of high-resolution MRI data takes long scan time at high system cost, and could be limited to low spatial coverage and also subject to motion artifacts. Super-resolution MRI can be achieved with deep learning, which is a promising approach and has a great potential for preclinical and clinical imaging. Compared with polynomial interpolation or sparse-coding algorithms, deep learning extracts prior knowledge from big data and produces superior MRI images from a low-resolution counterpart. In this paper, we adapt two state-of-the-art neural network models for CT denoising and deblurring, transfer them for super-resolution MRI, and demonstrate encouraging super-resolution MRI results toward two-fold resolution enhancement.},
	urldate = {2020-09-29},
	journal = {arXiv:1810.06776 [physics]},
	author = {Lyu, Qing and You, Chenyu and Shan, Hongming and Wang, Ge},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.06776},
	keywords = {Physics - Medical Physics}
}

@article{dias_metodos_nodate,
	title = {Métodos para {Reconstrução} de {Imagens} de {Tomografia} da {Coroa} {Solar} {Baseados} em},
	language = {pt},
	author = {Dias, Daniele},
	pages = {82},
	file = {Dias - Métodos para Reconstrução de Imagens de Tomografia.pdf:/home/gabrielziegler/Zotero/storage/LLMCVKWJ/Dias - Métodos para Reconstrução de Imagens de Tomografia.pdf:application/pdf}
}

@inproceedings{devlin_bert_2019,
	address = {Minneapolis, Minnesota},
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {https://www.aclweb.org/anthology/N19-1423},
	doi = {10.18653/v1/N19-1423},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2020-07-28},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = jun,
	year = {2019},
	pages = {4171--4186},
	file = {Full Text PDF:/home/gabrielziegler/Zotero/storage/BNPCGSTX/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf}
}

@incollection{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Nets}},
	url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
	urldate = {2020-07-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {2672--2680},
	file = {NIPS Full Text PDF:/home/gabrielziegler/Zotero/storage/FIPFYCKU/Goodfellow et al. - 2014 - Generative Adversarial Nets.pdf:application/pdf;NIPS Snapshot:/home/gabrielziegler/Zotero/storage/8EMLKE8Z/5423-generative-adversarial-nets.html:text/html}
}

@article{deshmane_parallel_2012,
	title = {Parallel {MR} imaging},
	volume = {36},
	issn = {10531807},
	url = {http://doi.wiley.com/10.1002/jmri.23639},
	doi = {10.1002/jmri.23639},
	language = {en},
	number = {1},
	urldate = {2021-03-06},
	journal = {Journal of Magnetic Resonance Imaging},
	author = {Deshmane, Anagha and Gulani, Vikas and Griswold, Mark A. and Seiberlich, Nicole},
	month = jul,
	year = {2012},
	pages = {55--72},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/ZCN7B243/Deshmane et al. - 2012 - Parallel MR imaging.pdf:application/pdf}
}

@article{eun_deep-learning-based_2020,
	title = {Deep-learning-based image quality enhancement of compressed sensing magnetic resonance imaging of vessel wall: comparison of self-supervised and unsupervised approaches},
	volume = {10},
	issn = {2045-2322},
	shorttitle = {Deep-learning-based image quality enhancement of compressed sensing magnetic resonance imaging of vessel wall},
	url = {http://www.nature.com/articles/s41598-020-69932-w},
	doi = {10.1038/s41598-020-69932-w},
	language = {en},
	number = {1},
	urldate = {2021-03-22},
	journal = {Scientific Reports},
	author = {Eun, Da-in and Jang, Ryoungwoo and Ha, Woo Seok and Lee, Hyunna and Jung, Seung Chai and Kim, Namkug},
	month = dec,
	year = {2020},
	pages = {13950},
	file = {Full Text:/home/gabrielziegler/Zotero/storage/HNMSDKN6/Eun et al. - 2020 - Deep-learning-based image quality enhancement of c.pdf:application/pdf}
}

@inproceedings{garcia-frias_exploiting_2007,
	address = {Snowbird, UT, USA},
	title = {Exploiting {Prior} {Knowledge} in {The} {Recovery} of {Signals} from {Noisy} {Random} {Projections}},
	isbn = {978-0-7695-2791-8},
	url = {http://ieeexplore.ieee.org/document/4148772/},
	doi = {10.1109/DCC.2007.37},
	abstract = {It has been recently shown that if a signal can be compressed in some basis, then it can be reconstructed in such basis from a certain number of random projections. By allowing additional distortion, this holds even if the projections are corrupted by noise. We extend this result by showing that it is possible to exploit prior knowledge (e.g., if the signal is a realization of a stochastic process,) to signiﬁcantly improve reconstruction performance. This is done in a fashion resembling standard joint source-channel coding of digital sources. Moreover, the exploitation of such knowledge allows for reconstruction in bases where the signal is not sparse.},
	language = {en},
	urldate = {2021-04-24},
	booktitle = {2007 {Data} {Compression} {Conference} ({DCC}'07)},
	publisher = {IEEE},
	author = {Garcia-Frias, Javier and Esnaola, Inaki},
	year = {2007},
	pages = {333--342},
	file = {Garcia-Frias and Esnaola - 2007 - Exploiting Prior Knowledge in The Recovery of Sign.pdf:/home/gabrielziegler/Zotero/storage/APV9QHKI/Garcia-Frias and Esnaola - 2007 - Exploiting Prior Knowledge in The Recovery of Sign.pdf:application/pdf}
}

@inproceedings{esnaola_exploiting_2007,
	address = {Baltimore, MD, USA},
	title = {Exploiting {Prior} {Knowledge} in the {Recovery} of {Non}-{Sparse} {Signals} from {Noisy} {Random} {Projections}},
	isbn = {978-1-4244-1037-8},
	url = {http://ieeexplore.ieee.org/document/4298402/},
	doi = {10.1109/CISS.2007.4298402},
	language = {en},
	urldate = {2021-04-24},
	booktitle = {2007 41st {Annual} {Conference} on {Information} {Sciences} and {Systems}},
	publisher = {IEEE},
	author = {Esnaola, Inaki and Garcia-Frias, Javier},
	month = mar,
	year = {2007},
	pages = {731--731},
	file = {Esnaola and Garcia-Frias - 2007 - Exploiting Prior Knowledge in the Recovery of Non-.pdf:/home/gabrielziegler/Zotero/storage/G2D4JBCF/Esnaola and Garcia-Frias - 2007 - Exploiting Prior Knowledge in the Recovery of Non-.pdf:application/pdf}
}

@book{carmi_compressed_2014,
	address = {Berlin, Heidelberg},
	series = {Signals and {Communication} {Technology}},
	title = {Compressed {Sensing} \& {Sparse} {Filtering}},
	isbn = {978-3-642-38397-7 978-3-642-38398-4},
	url = {http://link.springer.com/10.1007/978-3-642-38398-4},
	language = {en},
	urldate = {2021-05-09},
	publisher = {Springer Berlin Heidelberg},
	editor = {Carmi, Avishy Y. and Mihaylova, Lyudmila and Godsill, Simon J.},
	year = {2014},
	doi = {10.1007/978-3-642-38398-4},
	file = {Carmi et al. - 2014 - Compressed Sensing & Sparse Filtering.pdf:/home/gabrielziegler/Zotero/storage/BKBMKPUJ/Carmi et al. - 2014 - Compressed Sensing & Sparse Filtering.pdf:application/pdf}
}

@article{kutyniok_compressed_nodate,
	title = {Compressed {Sensing}},
	language = {en},
	author = {Kutyniok, Gitta and Eldar, Yonina C},
	pages = {558},
	file = {Kutyniok and Eldar - Compressed Sensing.pdf:/home/gabrielziegler/Zotero/storage/KHLG6YFL/Kutyniok and Eldar - Compressed Sensing.pdf:application/pdf}
}

@article{candes_near-optimal_2006,
	title = {Near-{Optimal} {Signal} {Recovery} {From} {Random} {Projections}: {Universal} {Encoding} {Strategies}?},
	volume = {52},
	issn = {0018-9448},
	shorttitle = {Near-{Optimal} {Signal} {Recovery} {From} {Random} {Projections}},
	url = {http://ieeexplore.ieee.org/document/4016283/},
	doi = {10.1109/TIT.2006.885507},
	language = {en},
	number = {12},
	urldate = {2021-05-09},
	journal = {IEEE Transactions on Information Theory},
	author = {Candes, Emmanuel J. and Tao, Terence},
	month = dec,
	year = {2006},
	pages = {5406--5425},
	file = {Candes and Tao - 2006 - Near-Optimal Signal Recovery From Random Projectio.pdf:/home/gabrielziegler/Zotero/storage/PSQ5I86F/Candes and Tao - 2006 - Near-Optimal Signal Recovery From Random Projectio.pdf:application/pdf}
}

@article{candes_robust_2006,
	title = {Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information},
	volume = {52},
	issn = {0018-9448},
	shorttitle = {Robust uncertainty principles},
	url = {http://ieeexplore.ieee.org/document/1580791/},
	doi = {10.1109/TIT.2005.862083},
	language = {en},
	number = {2},
	urldate = {2021-05-09},
	journal = {IEEE Transactions on Information Theory},
	author = {Candes, E.J. and Romberg, J. and Tao, T.},
	month = feb,
	year = {2006},
	pages = {489--509},
	file = {Candes et al. - 2006 - Robust uncertainty principles exact signal recons.pdf:/home/gabrielziegler/Zotero/storage/73WJ95F5/Candes et al. - 2006 - Robust uncertainty principles exact signal recons.pdf:application/pdf}
}
